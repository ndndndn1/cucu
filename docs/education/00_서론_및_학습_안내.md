# 모듈 0: 서론 및 학습 안내

---

## 1. 과정 개요: "6단계로 cuBLAS 90%에 도달하기"

이 교육 과정은 **BareMetal-SGEMM** 프로젝트를 기반으로, CUDA GPU에서 단정밀도
행렬곱(SGEMM, Single-precision General Matrix Multiply)을 처음부터 구현하고
단계적으로 최적화하여 NVIDIA의 cuBLAS 라이브러리 성능의 **90% 이상**에 도달하는
과정을 다룬다.

단순히 "빠른 코드"를 작성하는 것이 목표가 아니다. NVIDIA GPU의 하드웨어 특성을
**분석(Characterization)** 하고, 병목 지점을 **진단(Diagnosis)** 하며, 체계적으로
**최적화(Optimization)** 하는 실전 엔지니어링 프로세스를 학습한다. 이는 NVIDIA의
시스템 소프트웨어 엔지니어나 GPU 아키텍트가 실제로 수행하는 업무와 동일한 과정이다.

총 6개의 최적화 레벨을 거치며, 각 레벨에서는 하나의 핵심 최적화 기법을 도입한다.
나이브 구현(cuBLAS 대비 1-5%)에서 출발하여 비동기 복사(cuBLAS 대비 85-95%)에
도달하기까지, 매 단계에서 "왜 이 기법이 성능을 향상시키는가"를 하드웨어 수준에서
이해하게 된다.

---

## 2. 대상

- **C++ 기초 지식**을 가진 대학생 (포인터, 배열, 함수, 기본 자료구조 수준)
- GPU 프로그래밍 경험은 필요하지 않다. 사전지식 모듈(1-3)에서 필요한 배경을 모두
  다룬다.
- 선형대수 기초(행렬곱의 정의) 정도의 수학적 배경이면 충분하다.

---

## 3. 학습 로드맵

아래 다이어그램은 6단계 최적화 과정을 산 등반에 비유한 것이다. 각 레벨에서
달성하는 성능(GFLOP/s)과 cuBLAS 대비 비율을 함께 표시하였다.

```
                                                          cuBLAS (100%)
                                                        /  ~10000-11000 GFLOP/s
                                                   ___/
                                              ____/  |
                               Level 5       /       |
                              AsyncCopy  ___/        |
                             85-95%     /            |
                            ~7000-9500 /             |
                         _____________/              |
                        /                            |
           Level 4     /                             |
          DblBuffer   /                              |
          70-85%     /                               |
         ~4000-6000 /                                |
        ___________/                                 |
       /                                             |
      / Level 3                                      |
     /  RegBlock                                     |
    /   50-70%                                       |
   /   ~2000-3000                                    |
  /________                                          |
  |        \                                         |
  | Level 2 \                                        |
  | Tiled    \                                       |
  | 20-40%    |                                      |
  | ~800-1200 |                                      |
  |___________|                                      |
  |           |                                      |
  | Level 1   |      < 사전지식 모듈 1-3 >           |
  | Coalesced |      GPU 아키텍처 / CUDA 기초        |
  | 5-15%     |      행렬곱셈 수학적 배경            |
  | ~200-300  |______________________________________|
  |           |
  | Level 0   |
  | Naive     |
  | 1-5%      |
  | ~50-70    |
  |___________|
  =============
   Base Camp
   (C++ 기초)

  [단위: GFLOP/s, A100 기준 예상치]
```

**핵심 메시지**: 각 레벨 사이의 성능 격차는 "더 열심히 코딩하는 것"이 아니라,
**하드웨어 특성에 대한 이해의 깊이**에서 비롯된다. Level 0에서 Level 5까지의 코드
분량 차이는 크지 않지만, 성능 차이는 100배 이상이다.

---

## 4. 적용 교육 이론 안내

이 교육 과정은 학습 효과를 극대화하기 위해 다음 8가지 교육 이론을 체계적으로
적용하였다. 각 이론이 어떤 방식으로, 어디에 반영되어 있는지 간략히 안내한다.

### 4.1 Bloom's Taxonomy (블룸의 분류 체계)

**핵심**: 인지 수준을 점진적으로 상승시킨다.

Remember(기억) -> Understand(이해) -> Apply(적용) -> Analyze(분석) -> Evaluate(평가) -> Create(창조)

초반 모듈에서는 용어와 개념을 기억하고 이해하는 데 초점을 맞추고, 후반 모듈로
갈수록 분석, 평가, 창조 수준의 과제를 부여한다. 퀴즈 또한 이 6단계에 맞추어
난이도를 분배하였다.

### 4.2 Cognitive Load Theory (인지 부하 이론)

**핵심**: 모듈당 신규 개념을 3개 이하로 제한한다.

GPU 최적화는 한꺼번에 배우기엔 개념이 너무 많다. 각 모듈에서 도입하는 새로운
개념을 최대 3개로 제한하고, 한글 용어와 영문 원어를 병기하여 불필요한 인지 부하
(extraneous load)를 줄인다. 이미 배운 내용은 반복하여 내재적 부하(intrinsic
load)를 낮춘다.

### 4.3 Worked Example Effect (완전예제 효과)

**핵심**: 완전예제 -> 주석예제 -> 부분예제 -> 독립과제 순서로 점진적으로 자립도를
높인다.

Level 0-2에서는 코드를 라인별로 완전히 해설하는 "완전 워크스루"를 제공한다.
Level 3부터는 핵심 부분만 주석을 달고 나머지는 스스로 분석하게 하며, Level 5에
이르면 독립적으로 코드를 이해하고 수정할 수 있는 수준을 목표로 한다.

### 4.4 CRA Framework (구체-표상-추상 프레임워크)

**핵심**: 일상 비유 -> 다이어그램 -> 수식/코드 순서로 개념을 제시한다.

모든 핵심 개념은 먼저 **일상적인 비유**(예: "메모리 코얼레싱은 마트에서 한 번에
여러 물건을 카트에 담는 것과 같다")로 시작하고, **다이어그램**으로 시각화한 뒤,
마지막으로 **수식이나 코드**로 정확한 정의를 내린다.

### 4.5 Mastery Learning (완전학습)

**핵심**: 게이트 퀴즈에서 80% 이상을 통과해야 다음 단계로 진행한다.

Level 2(타일링), Level 4(더블 버퍼링), Level 5(비동기 복사) 이후에 마스터리
체크포인트를 배치하였다. 이 지점들은 이후 학습의 기반이 되는 핵심 개념이
집약되는 곳이므로, 충분한 이해 없이 넘어가면 이후 모듈에서 어려움을 겪게 된다.

### 4.6 Dual Coding (이중 부호화)

**핵심**: 시각 자료와 수식/코드를 동시에 제공한다.

텍스트만으로 설명하지 않는다. 모든 핵심 개념에는 ASCII 다이어그램 또는 도표가
함께 제공되며, 수식과 코드 스니펫이 동시에 나타난다. 시각 채널과 언어 채널을 함께
활용함으로써 기억의 정착률을 높인다.

### 4.7 Retrieval Practice (인출 연습)

**핵심**: 각 모듈 시작 시 이전 모듈의 사전 복습 퀴즈 3문항을 풀어본다.

단순히 "이전 내용을 다시 읽기"가 아니라, 능동적으로 기억에서 꺼내는(retrieval)
연습을 한다. 연구에 따르면 인출 연습은 재독(re-reading)보다 장기 기억 정착에
2-3배 효과적이다.

### 4.8 Elaborative Interrogation (정교화 질문)

**핵심**: "왜 이것이 작동하는가?" 질문으로 심층 이해를 유도한다.

매 모듈의 코드 분석 이후에 "왜 이 기법이 성능을 향상시키는가?"라는 심층 질문
3-5개를 제시한다. 단순히 "무엇(what)"을 아는 것에 그치지 않고, "왜(why)"를
설명할 수 있어야 진정한 이해에 도달한 것이다.

---

## 5. 모듈 구조 안내

모든 모듈은 다음 9개 섹션으로 통일된 구조를 따른다. 이 구조 자체가 위에서 설명한
교육 이론들을 체계적으로 반영한 것이다.

| 순서 | 섹션 이름 | 설명 | 적용 이론 |
|------|-----------|------|-----------|
| 1 | **학습 목표** | Bloom의 동사를 사용한 3-5개 목표 | Bloom's Taxonomy |
| 2 | **사전 복습** | 이전 1-2개 모듈의 인출 연습 3문항 | Retrieval Practice |
| 3 | **개념 설명** | 일상비유 -> 다이어그램 -> 수식/정의 | CRA + Dual Coding |
| 4 | **코드 분석** | 라인별 워크스루, 파일:라인 참조 | Worked Example |
| 5 | **왜 이것이 작동하는가?** | 심층 질문 3-5개 | Elaborative Interrogation |
| 6 | **시뮬레이션** | 종이/스프레드시트 기반 실습 | CRA (Concrete) |
| 7 | **핵심 정리** | 요약 불릿 포인트 | Cognitive Load Theory |
| 8 | **퀴즈** | Bloom 수준별 배분 문항 | Mastery Learning |
| 9 | **다음 단계 미리보기** | 다음 레벨의 동기부여 | - |

---

## 6. 빌드 및 실행 방법

이 프로젝트의 빌드와 실행에 관한 자세한 내용은 프로젝트 루트의 `CMakeLists.txt`와
`scripts/build.sh`를 참조한다.

### 6.1 빌드

```bash
# 빌드 스크립트를 사용한 빌드 (권장)
# 첫 번째 인자: 빌드 타입 (Release/Debug)
# 두 번째 인자: 타겟 SM 아키텍처 (80 = A100/RTX 30 시리즈)
./scripts/build.sh Release 80
```

빌드가 완료되면 `build/` 디렉토리에 다음 실행 파일이 생성된다.
- `build/sgemm_benchmark` : 성능 벤치마크
- `build/sgemm_test` : 정확성 테스트

### 6.2 벤치마크 실행

```bash
# 4096x4096 행렬에 대한 전체 벤치마크 (cuBLAS 비교 포함)
./build/sgemm_benchmark -m 4096 -n 4096 -k 4096 -c
```

주요 옵션:
- `-m`, `-n`, `-k` : 행렬 크기 (C = A[M x K] * B[K x N])
- `-c` : cuBLAS 레퍼런스 비교 포함
- `-l <레벨>` : 특정 최적화 레벨만 실행 (예: `-l 5`는 AsyncCopy만)
- `-s` : 다양한 행렬 크기에 대해 테스트

### 6.3 정확성 테스트

```bash
# 모든 최적화 레벨의 계산 정확성 검증
./build/sgemm_test
```

벤치마크를 통해 성능을 측정하기 전에, 반드시 정확성 테스트를 통과하는지 확인해야
한다. 아무리 빨라도 결과가 틀리면 의미가 없다.

---

## 7. 성능 목표 표

아래 표는 A100 GPU 기준으로 각 최적화 레벨에서 기대할 수 있는 성능이다. 실제
수치는 GPU 모델, 드라이버 버전, 행렬 크기 등에 따라 달라질 수 있다.

| 행렬 크기 | Naive | Coalesced | Tiled | RegBlock | DblBuffer | AsyncCopy | cuBLAS |
|-----------|-------|-----------|-------|----------|-----------|-----------|--------|
| 1024^3    | 50    | 200       | 800   | 2000     | 4000      | 7000      | 8000   |
| 2048^3    | 60    | 250       | 1000  | 2500     | 5000      | 8500      | 10000  |
| 4096^3    | 70    | 300       | 1200  | 3000     | 6000      | 9500      | 11000  |

*(단위: GFLOP/s, A100 기준 예상치)*

| 최적화 레벨 | cuBLAS 대비 비율 | 핵심 기법 | 도입 개념 |
|-------------|-----------------|-----------|-----------|
| Level 0 (Naive) | 1-5% | 기본 구현 | 스레드-원소 매핑 |
| Level 1 (Coalesced) | 5-15% | 메모리 코얼레싱 | float4, 128-bit 로드 |
| Level 2 (Tiled) | 20-40% | 공유 메모리 타일링 | __shared__, 뱅크 충돌 |
| Level 3 (RegBlock) | 50-70% | 레지스터 블로킹 | 외적 마이크로커널, 산술 강도 |
| Level 4 (DblBuffer) | 70-85% | 더블 버퍼링 | 레이턴시 은닉, 프롤로그 |
| Level 5 (AsyncCopy) | 85-95% | 비동기 복사 | cp.async, 트리플 버퍼 |

**관찰 포인트**: Level 0에서 Level 5까지 코드 줄 수는 약 75줄에서 450줄로 6배
증가하지만, 성능은 약 100배 이상 향상된다. 성능 향상의 핵심은 코드의 양이 아니라
**하드웨어를 얼마나 잘 활용하는가**에 달려 있다.

---

## 8. 필요 도구

이 프로젝트를 빌드하고 실행하기 위해 다음 도구가 필요하다.

| 도구 | 최소 버전 | 비고 |
|------|-----------|------|
| CUDA Toolkit | 11.0+ | Level 5의 cp.async 기능 사용 시 11.1 이상 필요 |
| CMake | 3.18+ | CUDA 언어 네이티브 지원에 필요 |
| GCC | 9+ | 또는 Clang 10 이상 |
| NVIDIA GPU | Compute Capability 7.0+ | Ampere(SM 8.0) 이상 권장 |

**Ampere 이상 GPU 권장 이유**: Level 5의 `cp.async` 명령어는 Ampere 아키텍처
(SM 8.0) 이상에서만 하드웨어로 지원된다. 이전 아키텍처에서는 Level 0-4까지만
실행 가능하다.

성능 분석에 활용할 수 있는 추가 도구:
- **NVIDIA Nsight Compute**: 커널 수준 프로파일링 (SOL 분석, 스톨 원인 분석)
- **NVIDIA Nsight Systems**: 시스템 수준 타임라인 분석
- **cuobjdump**: PTX/SASS 코드 추출 및 검사

---

## 9. 문서 목록

아래는 `docs/education/` 디렉토리에 포함된 전체 14개 문서의 목록과 각 문서의
역할이다. 순서대로 학습하는 것을 권장한다.

| 번호 | 파일명 | 내용 |
|------|--------|------|
| 00 | `00_서론_및_학습_안내.md` | 과정 개요, 학습 로드맵, 빌드 방법, 교육 이론 안내 (현재 문서) |
| 01 | `01_사전지식_GPU_아키텍처.md` | CPU vs GPU 비교, SM 구조, 워프, 메모리 계층, 점유율 |
| 02 | `02_사전지식_CUDA_프로그래밍_기초.md` | Runtime API vs Driver API, 컨텍스트, PTX, 메모리 관리, 커널 런치 |
| 03 | `03_사전지식_행렬곱셈_수학적_배경.md` | SGEMM 정의, Row-major 저장, FLOP 계산, 산술 강도, 루프라인 모델 |
| 04 | `04_Level0_나이브_구현.md` | 기본 SGEMM 커널, 라인별 워크스루, 성능 병목 3가지 분석 |
| 05 | `05_Level1_메모리_코얼레싱.md` | float4 벡터화, 128-bit 로드, SASS LDG.E.128 확인 |
| 06 | `06_Level2_공유_메모리_타일링.md` | 타일링, 협력적 로딩, 뱅크 충돌 분석, 마스터리 체크포인트 1 |
| 07 | `07_Level3_레지스터_블로킹.md` | 스레드 조잡화, 외적 마이크로커널, 산술 강도 향상 |
| 08 | `08_Level4_더블_버퍼링.md` | 레이턴시 은닉, 이중 버퍼, 프롤로그-메인루프, 마스터리 체크포인트 2 |
| 09 | `09_Level5_비동기_복사.md` | cp.async, 트리플 버퍼, LDGSTS, 최종 마스터리 체크포인트 |
| 10 | `10_종합_성능분석_및_프로파일링.md` | Nsight Compute, SOL 분석, 루프라인 모델, 튜닝 의사결정 트리 |
| 11 | `11_부록_용어_사전.md` | 50개 이상의 용어: 영문, 한글, 정의, 코드 참조, 첫 등장 모듈 |
| 12 | `12_부록_퀴즈_정답.md` | 전 모듈 약 70문항의 상세 해설 정답 |
| 13 | `13_부록_시뮬레이션_가이드.md` | 10종 시뮬레이션의 상세 수행 절차, 필요 도구, 예상 결과 |

**권장 학습 순서**:
1. 본 문서(모듈 0)를 읽고 전체 구조를 파악한다.
2. 사전지식 모듈(01-03)을 순서대로 학습한다.
3. 최적화 레벨 모듈(04-09)을 순서대로 학습한다. 각 레벨은 이전 레벨에 의존한다.
4. 종합 성능분석(10)으로 전체를 통합한다.
5. 부록(11-13)은 학습 중 수시로 참조한다.

---

*이 교육 과정은 BareMetal-SGEMM 프로젝트의 코드베이스를 기반으로 하며,
대학생이 백지 상태에서 출발하여 전문 엔지니어 수준의 GPU 최적화 역량을
갖추는 것을 목표로 한다.*
