# 모듈 3: 사전지식 -- 행렬곱셈 수학적 배경

> SGEMM 최적화를 시작하기 전에 반드시 알아야 하는 수학적 기초를 다룬다.
> 행렬곱셈의 정의, 메모리 레이아웃, 연산량 계산, 산술 강도, 루프라인 모델을
> 이해해야 이후 최적화 단계에서 "왜 빨라지는가"를 정량적으로 분석할 수 있다.

---

## 1. 학습 목표

이 모듈을 완료하면 다음을 할 수 있다.

| 번호 | 목표 | Bloom 수준 |
|------|------|-----------|
| 1 | SGEMM 연산 (C = alpha * A * B + beta * C)을 수학적으로 정의할 수 있다 | 이해 |
| 2 | Row-major 메모리 레이아웃에서의 행렬 인덱싱을 이해한다 | 이해 |
| 3 | SGEMM의 FLOP 수를 계산할 수 있다 (2 * M * N * K) | 적용 |
| 4 | 산술 강도(Arithmetic Intensity)를 계산할 수 있다 | 적용 |
| 5 | 루프라인 모델(Roofline Model)을 해석할 수 있다 | 분석 |

---

## 2. 사전 복습

모듈 1~2의 핵심 내용을 복습한다. 아래 질문에 즉시 답할 수 있어야 한다.

**질문 1.** 글로벌 메모리와 공유 메모리의 접근 지연시간 차이는 대략 얼마인가?

> 글로벌 메모리는 약 400~600 사이클, 공유 메모리는 약 20~30 사이클이다.
> 약 20배의 지연시간 차이가 존재한다.

**질문 2.** CUDA Driver API에서 커널을 실행(launch)하는 함수의 이름은 무엇인가?

> `cuLaunchKernel()` 이다. Runtime API의 `<<<>>>` 구문과 달리
> 명시적으로 그리드/블록 크기, 공유 메모리 크기, 스트림, 커널 파라미터를 전달한다.

**질문 3.** GPU SM당 공유 메모리의 크기는 대략 얼마인가?

> Ampere 기준 최대 164KB까지 구성 가능하며, 기본값은 48KB이다.
> L1 캐시와 공유 메모리가 동일한 온칩 SRAM을 분할 사용한다.

---

## 3. 개념 설명

### 3.1 행렬곱셈 정의

SGEMM(Single-precision General Matrix Multiplication)은 다음 연산을 수행한다.

```
C = alpha * A * B + beta * C
```

여기서 각 행렬의 차원은 다음과 같다.

| 행렬 | 행(rows) | 열(cols) | 원소 수 |
|------|---------|---------|--------|
| A | M | K | M * K |
| B | K | N | K * N |
| C | M | N | M * N |

출력 행렬 C의 각 원소 C[i][j]는 다음과 같이 계산된다.

```
C[i][j] = alpha * SUM(A[i][k] * B[k][j], k = 0 .. K-1) + beta * C[i][j]
```

즉, A의 i번째 행과 B의 j번째 열의 내적(dot product)에 alpha를 곱하고, 기존 C[i][j]에 beta를 곱한 값을 더한다.

**코드 참조**: `include/sgemm_kernels.hpp:109-126` -- `SgemmParams` 구조체

```cpp
struct SgemmParams {
    int M;              // A와 C의 행 수
    int N;              // B와 C의 열 수
    int K;              // A의 열 수, B의 행 수
    float alpha;        // A*B에 곱하는 스칼라
    float beta;         // C에 곱하는 스칼라
    CUdeviceptr A;      // A의 디바이스 포인터 (MxK, row-major)
    CUdeviceptr B;      // B의 디바이스 포인터 (KxN, row-major)
    CUdeviceptr C;      // C의 디바이스 포인터 (MxN, row-major)
    int lda;            // A의 leading dimension (보통 K)
    int ldb;            // B의 leading dimension (보통 N)
    int ldc;            // C의 leading dimension (보통 N)
};
```

M, N, K는 행렬의 차원을 정의하고, alpha와 beta는 스칼라 계수이며, A/B/C는 GPU 메모리의 디바이스 포인터이다. lda/ldb/ldc는 각 행렬의 leading dimension으로, row-major에서 행과 행 사이의 간격을 나타낸다.

---

### 3.2 Row-major 저장

2차원 행렬은 1차원 메모리에 저장해야 한다. Row-major 방식에서는 행(row) 단위로 연속 저장한다.

**인덱싱 공식:**

```
A[i][j] = memory[i * cols + j]
```

여기서 `cols`는 행렬의 열 수이다.

**코드 참조**: `src/kernels/sgemm_naive.cu:44`

```cpp
sum += A[row * lda + k] * B[k * ldb + col];
```

`row * lda + k`에서 `lda`는 A의 leading dimension이다. Row-major에서 leading dimension은 열 수(K)와 같다.

**코드 참조**: `include/sgemm_kernels.hpp:118-120`

```cpp
int lda;    // Leading dimension of A (usually K)
int ldb;    // Leading dimension of B (usually N)
int ldc;    // Leading dimension of C (usually N)
```

**Leading Dimension(리딩 디멘션)** 이란 행렬에서 한 행의 첫 원소에서 다음 행의 첫 원소까지의 메모리 간격(원소 단위)이다. Row-major에서는 열 수와 같다. 패딩이 있을 경우에는 열 수보다 클 수 있다.

**ASCII 다이어그램 -- 4x3 행렬의 Row-major 메모리 레이아웃:**

```
논리적 행렬 (4행 x 3열):

         col0  col1  col2
row0  [  a     b     c  ]
row1  [  d     e     f  ]
row2  [  g     h     i  ]
row3  [  j     k     l  ]

물리적 메모리 (1차원, 연속):

주소:  0   1   2   3   4   5   6   7   8   9  10  11
     [ a | b | c | d | e | f | g | h | i | j | k | l ]
       ^           ^           ^           ^
      row0        row1        row2        row3
       |           |           |           |
     0*3=0       1*3=3       2*3=6       3*3=9

lda = 3 (열 수)
A[2][1] = memory[2 * 3 + 1] = memory[7] = h
```

핵심 관찰: Row-major에서 같은 행의 원소들은 메모리에서 연속이지만, 같은 열의 원소들은 `lda`만큼의 간격을 두고 떨어져 있다. 이는 GPU의 메모리 접근 패턴에 중대한 영향을 미친다.

---

### 3.3 FLOP 계산

SGEMM의 연산량을 정확히 세어보자.

**단일 출력 원소 C[i][j]의 연산:**

```
C[i][j] = alpha * SUM(A[i][k] * B[k][j], k=0..K-1) + beta * C[i][j]
```

- 내적 계산: K번의 곱셈 + K번의 덧셈 = 2K FLOP
- alpha 곱셈: 1 FLOP
- beta 곱셈: 1 FLOP
- 최종 덧셈: 1 FLOP

정확한 총 FLOP 수는 `M * N * (2K + 3)`이지만, K가 충분히 크면 +3은 무시할 수 있으므로 관례적으로 다음과 같이 계산한다.

```
총 FLOP = 2 * M * N * K
```

**FMA(Fused Multiply-Add)와의 관계:**

GPU는 `a * b + c`를 단일 FMA 명령어로 수행한다. FMA 하나가 곱셈 1회 + 덧셈 1회 = 2 FLOP에 해당한다. 따라서 내적의 K번 반복은 K번의 FMA로 구현되며, 이것이 2K FLOP이다.

**코드 참조**: `include/sgemm_kernels.hpp:195-198` -- `sgemm_flops()` 함수

```cpp
// Calculate FLOP count for SGEMM
inline double sgemm_flops(int M, int N, int K) {
    // Each output element requires K FMAs (2 ops each) + beta scaling
    return 2.0 * M * N * K;
}
```

---

### 3.4 메모리 트래픽 계산

커널이 수행해야 하는 최소 메모리 전송량을 계산한다. "최소"라 함은 모든 데이터를 정확히 한 번만 읽고 쓰는 이상적인 경우를 의미한다.

| 연산 | 행렬 | 원소 수 | 바이트 (float = 4B) |
|------|------|---------|-------------------|
| 읽기 | A | M * K | 4 * M * K |
| 읽기 | B | K * N | 4 * K * N |
| 읽기 | C (beta 곱셈용) | M * N | 4 * M * N |
| 쓰기 | C (결과 저장) | M * N | 4 * M * N |
| **합계** | | | **4 * (M*K + K*N + 2*M*N)** |

**코드 참조**: `include/sgemm_kernels.hpp:201-204` -- `sgemm_min_bytes()` 함수

```cpp
// Calculate minimum memory traffic (bytes)
inline double sgemm_min_bytes(int M, int N, int K) {
    // Read A (MxK), B (KxN), C (MxN), Write C (MxN)
    return sizeof(float) * (M * K + K * N + 2 * M * N);
}
```

주의: 이것은 이론적 최소값이다. 실제 커널에서는 캐시 미스, 데이터 재사용 부재, 비정렬 접근 등으로 인해 이보다 훨씬 많은 메모리 트래픽이 발생한다.

---

### 3.5 산술 강도 (Arithmetic Intensity)

산술 강도(AI)는 전송된 바이트당 수행하는 부동소수점 연산 수이다.

```
AI = FLOP / Bytes = (2 * M * N * K) / (4 * (M*K + K*N + 2*M*N))
```

**정사각 행렬 (M = N = K = n) 에서의 단순화:**

```
AI = 2 * n^3 / (4 * (n^2 + n^2 + 2*n^2))
   = 2 * n^3 / (4 * 4 * n^2)
   = 2 * n^3 / (16 * n^2)
   = n / 8
```

| 행렬 크기 (n) | 이론적 산술 강도 (FLOP/byte) |
|--------------|---------------------------|
| 256 | 32 |
| 512 | 64 |
| 1024 | 128 |
| 2048 | 256 |
| 4096 | 512 |

n이 커질수록 산술 강도가 선형으로 증가한다. 이것이 행렬곱셈이 큰 크기에서 반드시 연산 바운드(compute-bound)가 될 수 있는 수학적 근거이다.

**코드 참조**: `include/sgemm_kernels.hpp:187` -- `SgemmMetrics::arithmetic_intensity`

```cpp
double arithmetic_intensity; // FLOP per byte
```

주의: 위 표의 산술 강도는 "이론적 최소 메모리 트래픽" 기준이다. 실제 커널에서 달성하는 유효 산술 강도(effective AI)는 데이터 재사용률에 따라 달라진다.

---

### 3.6 루프라인 모델 (Roofline Model)

루프라인 모델은 커널의 성능 상한을 두 가지 하드웨어 한계의 함수로 나타낸다.

```
달성 가능 성능 (GFLOP/s) <= min(피크 연산 처리량, 피크 메모리 대역폭 * 산술 강도)
```

**두 가지 영역:**

- **메모리 바운드 영역**: 산술 강도가 낮으면 성능이 대역폭에 의해 제한된다
- **연산 바운드 영역**: 산술 강도가 높으면 성능이 연산 유닛에 의해 제한된다

**릿지 포인트(Ridge Point)** 는 두 영역의 경계점이다.

```
릿지 포인트 = 피크 연산 처리량 / 피크 메모리 대역폭
```

예를 들어 GPU의 피크 연산이 19,500 GFLOP/s이고 피크 대역폭이 768 GB/s라면:

```
릿지 포인트 = 19500 / 768 = 25.4 FLOP/byte
```

**ASCII 루프라인 다이어그램:**

```
성능
(GFLOP/s)
    ^
    |
    |                          ____________________________  <-- 피크 연산 처리량
    |                        /
    |                      /
    |                    /     연산 바운드 영역
    |                  /       (더 이상 빨라지지 않음)
    |                /
    |              /
    |            /
    |          /  <-- 기울기 = 피크 메모리 대역폭
    |        /
    |      /   메모리 바운드 영역
    |    /     (대역폭이 병목)
    |  /
    |/
    +-----|----------------------------------------------------> 산술 강도
          ^                                                     (FLOP/byte)
      릿지 포인트
```

**최적화 수준별 유효 산술 강도 변화:**

각 최적화는 동일한 2*M*N*K FLOP을 수행하면서 실제 메모리 트래픽을 줄인다. 이는 유효 산술 강도를 높이는 것과 같다.

| 최적화 수준 | 핵심 개선 | 유효 AI (대략) | 루프라인 위치 |
|------------|----------|--------------|-------------|
| Naive (Level 0) | 없음 (데이터 재사용 없음) | ~0.25 FLOP/byte | 메모리 바운드 영역, 매우 왼쪽 |
| Tiled (Level 2) | 공유 메모리에 타일 적재 -> 재사용 증가 | ~2.0 FLOP/byte | 메모리 바운드 영역, 오른쪽으로 이동 |
| Register Blocking (Level 3) | 레지스터 수준 재사용 | ~8.0 FLOP/byte | 릿지 포인트 근처 또는 초과 |
| Double Buffer (Level 4+) | 메모리 지연시간 은닉 | ~8.0+ FLOP/byte | 연산 바운드 영역 진입 |

**핵심 통찰**: 최적화의 목표는 커널을 루프라인 다이어그램에서 오른쪽(더 높은 유효 AI)으로 이동시키는 것이다. 릿지 포인트를 넘어서면 더 이상 메모리가 아닌 연산이 병목이 된다.

---

### 3.7 왜 SGEMM이 최적화 대상으로 적합한가

행렬곱셈은 GPU 최적화를 학습하기에 이상적인 문제이다. 그 이유는 다음과 같다.

**1. 연산량 대비 데이터량의 비대칭성**

| 항목 | 복잡도 | n=4096일 때 |
|------|--------|-----------|
| 연산량 (FLOP) | O(n^3) | ~137.4 GFLOP |
| 데이터량 (원소 수) | O(n^2) | ~50.3M 원소 |
| 이론적 산술 강도 | O(n) | 512 FLOP/byte |

연산이 O(n^3)이고 데이터가 O(n^2)이므로, n이 커질수록 산술 강도가 O(n)으로 무한히 증가한다. 이는 충분히 큰 n에서 반드시 연산 바운드가 될 수 있음을 보장한다. 릿지 포인트가 아무리 높아도 n을 키우면 넘을 수 있다.

**2. 타일링의 효과가 이론적으로 보장됨**

타일 크기를 T라 하면, 타일 하나에서의 산술 강도는 대략 T에 비례한다. 따라서 타일 크기를 키울수록(하드웨어 제약 내에서) 산술 강도가 올라간다.

**3. 실용적 중요성**

SGEMM은 딥러닝의 모든 완전 연결 계층(fully connected layer), 합성곱 연산(im2col + GEMM), 어텐션 메커니즘 등의 핵심 연산이다. 이 하나의 커널을 최적화하면 실제 응용에 직접적인 성능 향상을 가져온다.

---

## 4. 코드 분석

이 모듈과 관련된 핵심 코드를 분석한다.

### 4.1 SgemmParams 구조체

**파일**: `include/sgemm_kernels.hpp:109-126`

```cpp
struct SgemmParams {
    int M;              // A와 C의 행 수
    int N;              // B와 C의 열 수
    int K;              // A의 열 수, B의 행 수
    float alpha;        // A*B에 곱하는 스칼라
    float beta;         // C에 곱하는 스칼라
    CUdeviceptr A;      // A의 디바이스 포인터 (MxK, row-major)
    CUdeviceptr B;      // B의 디바이스 포인터 (KxN, row-major)
    CUdeviceptr C;      // C의 디바이스 포인터 (MxN, row-major)
    int lda;            // A의 leading dimension (보통 K)
    int ldb;            // B의 leading dimension (보통 N)
    int ldc;            // C의 leading dimension (보통 N)

    SgemmParams(int m, int n, int k, float a, float b,
                CUdeviceptr pA, CUdeviceptr pB, CUdeviceptr pC)
        : M(m), N(n), K(k), alpha(a), beta(b),
          A(pA), B(pB), C(pC), lda(k), ldb(n), ldc(n) {}
};
```

**분석:**

- 생성자에서 `lda(k), ldb(n), ldc(n)`으로 초기화한다. 이는 패딩 없는 row-major 레이아웃을 가정한 것이다.
- `CUdeviceptr`은 CUDA Driver API의 디바이스 메모리 포인터 타입이다. Runtime API의 `float*`와 달리 정수형으로 표현된다.
- alpha와 beta는 BLAS 표준을 따르는 스칼라 계수이다. alpha=1.0, beta=0.0이면 단순한 C = A * B가 된다.

### 4.2 sgemm_flops() 함수

**파일**: `include/sgemm_kernels.hpp:195-198`

```cpp
inline double sgemm_flops(int M, int N, int K) {
    return 2.0 * M * N * K;
}
```

**분석:**

- M * N개의 출력 원소 각각에 K번의 FMA(2 FLOP)를 수행하므로 총 2*M*N*K FLOP이다.
- `double` 반환 타입을 사용하여 큰 행렬(예: 4096^3 = ~137.4G FLOP)에서도 오버플로 없이 정확한 값을 얻는다.
- `2.0`을 double 리터럴로 사용하여 정수 오버플로를 방지한다.

### 4.3 sgemm_min_bytes() 함수

**파일**: `include/sgemm_kernels.hpp:201-204`

```cpp
inline double sgemm_min_bytes(int M, int N, int K) {
    return sizeof(float) * (M * K + K * N + 2 * M * N);
}
```

**분석:**

- `sizeof(float)` = 4바이트를 곱하여 바이트 단위로 변환한다.
- `M * K`: A 읽기, `K * N`: B 읽기, `M * N`: C 읽기(beta 연산), `M * N`: C 쓰기
- 이 값은 이론적 하한이다. 캐시가 완벽하게 동작하여 모든 데이터를 정확히 한 번만 전송할 때의 값이다.

### 4.4 SgemmMetrics 구조체

**파일**: `include/sgemm_kernels.hpp:183-192`

```cpp
struct SgemmMetrics {
    double elapsed_ms;            // 커널 실행 시간 (밀리초)
    double gflops;               // 달성된 GFLOP/s
    double memory_bandwidth_gb;  // 달성된 메모리 대역폭 (GB/s)
    double arithmetic_intensity; // FLOP/byte
    double efficiency_vs_peak;   // 피크 대비 효율 (%)
    double efficiency_vs_cublas; // cuBLAS 대비 효율 (%)

    void print() const;
};
```

**각 필드의 계산 방법:**

| 필드 | 계산식 |
|------|--------|
| `elapsed_ms` | GPU 이벤트 타이머로 측정 |
| `gflops` | `sgemm_flops(M,N,K) / (elapsed_ms * 1e6)` |
| `memory_bandwidth_gb` | `sgemm_min_bytes(M,N,K) / (elapsed_ms * 1e6)` |
| `arithmetic_intensity` | `sgemm_flops(M,N,K) / sgemm_min_bytes(M,N,K)` |
| `efficiency_vs_peak` | `gflops / 피크_GFLOPS * 100` |
| `efficiency_vs_cublas` | `gflops / cublas_gflops * 100` |

---

## 5. 왜 이것이 작동하는가?

이 절에서는 깊은 이해를 위한 질문과 답변을 다룬다.

### 질문 1. FLOP 수가 2*M*N*K인데, alpha와 beta 연산은 왜 무시하는가?

alpha 곱셈(1 FLOP)과 beta 곱셈(1 FLOP)과 최종 덧셈(1 FLOP)을 포함하면 정확한 FLOP 수는 `M * N * (2K + 3)`이다. 그러나 K가 수백~수천일 때 2K에 비해 3은 무시할 수 있다. 예를 들어 K=1024이면 오차는 3/2048 = 0.15%에 불과하다. 또한 이 관례는 BLAS 표준과 학술 문헌에서 널리 사용되어 다른 구현과의 비교를 용이하게 한다.

### 질문 2. 실제 메모리 트래픽이 sgemm_min_bytes()보다 훨씬 큰 이유는?

`sgemm_min_bytes()`는 모든 데이터가 정확히 한 번만 전송된다고 가정한다. 그러나 실제로는:

- **데이터 재사용 부재**: Naive 커널에서 A의 각 원소는 N번, B의 각 원소는 M번 읽힌다. 이는 캐시에서 히트되지 않으면 실제 DRAM 트래픽이 이론치의 수백 배가 될 수 있다.
- **캐시 라인 낭비**: 128바이트 캐시 라인 중 일부만 사용하고 폐기하면 불필요한 전송이 발생한다.
- **비정렬 접근**: 정렬되지 않은 접근은 추가 캐시 라인 전송을 유발한다.

최적화의 핵심은 이 실제 트래픽을 이론적 최소값에 가깝게 줄이는 것이다.

### 질문 3. 산술 강도가 같은 두 커널의 성능이 다를 수 있는 이유는?

산술 강도는 FLOP/byte 비율만 나타낼 뿐, 다음 요소를 반영하지 않는다.

- **메모리 접근 패턴**: 코얼레싱(coalesced) 여부에 따라 같은 바이트 수라도 실제 대역폭 활용률이 다르다.
- **명령어 수준 병렬성(ILP)**: FMA 명령어 사이의 의존성 여부가 파이프라인 활용률을 결정한다.
- **뱅크 충돌**: 공유 메모리 뱅크 충돌은 산술 강도에 포함되지 않지만 성능을 크게 저하시킨다.
- **점유율과 레이턴시 은닉**: 충분한 워프가 없으면 메모리 레이턴시를 숨기지 못한다.

따라서 산술 강도는 성능의 상한만 제시하며, 실제 성능은 구현의 품질에 달려 있다.

### 질문 4. n이 충분히 크면 행렬곱이 반드시 compute-bound가 되는 이유는?

정사각 행렬에서 이론적 산술 강도가 n/8이므로, n이 커질수록 AI가 무한히 증가한다. 릿지 포인트가 아무리 높아도 (예: 25.4 FLOP/byte) n = 25.4 * 8 = 203.2, 즉 n >= 204이면 이론적으로 릿지 포인트를 넘는다.

물론 이것은 이론적 최소 메모리 트래픽 기준이다. 실제 커널의 유효 AI는 최적화 수준에 따라 달라지며, 최적화가 잘 된 커널일수록 이론치에 가까워진다. 그러나 핵심은 O(n^3) 연산 대 O(n^2) 데이터라는 근본적 비대칭성이 compute-bound의 가능성을 수학적으로 보장한다는 것이다.

---

## 6. 시뮬레이션 3: FLOP 계산기

### 예제 1: 직사각 행렬

**주어진 조건:** M=1024, N=2048, K=512

**1단계: 총 FLOP 수 계산**

```
총 FLOP = 2 * M * N * K
       = 2 * 1024 * 2048 * 512
       = 2,147,483,648
       = 약 2.15 GFLOP
```

**2단계: 성능 계산 (커널 실행 시간 0.5ms 가정)**

```
GFLOP/s = 총 FLOP / (실행시간(초) * 10^9)
        = 2,147,483,648 / (0.0005 * 1,000,000,000)
        = 2,147,483,648 / 500,000
        = 4,294.97
        = 약 4,295 GFLOP/s
```

**3단계: 최소 메모리 트래픽 계산**

```
최소 바이트 = 4 * (M*K + K*N + 2*M*N)
           = 4 * (1024*512 + 512*2048 + 2*1024*2048)
           = 4 * (524,288 + 1,048,576 + 4,194,304)
           = 4 * 5,767,168
           = 23,068,672 바이트
           = 약 23.07 MB
```

**4단계: 이론적 산술 강도 계산**

```
AI = FLOP / Bytes
   = 2,147,483,648 / 23,068,672
   = 93.1 FLOP/byte
```

**결과 요약:**

| 항목 | 값 |
|------|-----|
| 총 FLOP | 2,147,483,648 (약 2.15 GFLOP) |
| GFLOP/s (0.5ms 기준) | 약 4,295 |
| 최소 메모리 트래픽 | 23,068,672 바이트 (약 23.07 MB) |
| 이론적 산술 강도 | 93.1 FLOP/byte |

### 예제 2: 정사각 행렬

**주어진 조건:** M=N=K=4096

**1단계: 총 FLOP 수 계산**

```
총 FLOP = 2 * 4096 * 4096 * 4096
       = 2 * 4096^3
       = 2 * 68,719,476,736
       = 137,438,953,472
       = 약 137.44 GFLOP
```

**2단계: 최소 메모리 트래픽 계산**

```
최소 바이트 = 4 * (4096*4096 + 4096*4096 + 2*4096*4096)
           = 4 * (16,777,216 + 16,777,216 + 33,554,432)
           = 4 * 67,108,864
           = 268,435,456 바이트
           = 약 268.44 MB
```

**3단계: 이론적 산술 강도**

```
AI = 137,438,953,472 / 268,435,456
   = 512 FLOP/byte

검산: n/8 = 4096/8 = 512  (일치)
```

**4단계: 다양한 실행 시간에서의 성능**

| 실행 시간 | GFLOP/s | 피크 19,500 GFLOP/s 대비 |
|----------|---------|----------------------|
| 50.0 ms | 2,749 | 14.1% |
| 10.0 ms | 13,744 | 70.5% |
| 7.05 ms | 19,496 | 100.0% (이론적 한계) |

**연습 문제:** M=N=K=4096, 실행 시간 2.0ms일 때 GFLOP/s를 직접 계산해 보라.

```
GFLOP/s = 137,438,953,472 / (0.002 * 10^9) = 68,719.5 GFLOP/s
```

(이 값은 현존하는 단일 GPU의 피크를 초과한다. 실행 시간 2.0ms는 비현실적으로 짧은 것이다.)

---

## 7. 핵심 정리

이 모듈에서 다룬 핵심 내용을 정리한다.

| 주제 | 핵심 공식/개념 |
|------|--------------|
| SGEMM 정의 | C = alpha * A * B + beta * C (A: MxK, B: KxN, C: MxN) |
| Row-major 인덱싱 | A[i][j] = memory[i * lda + j] |
| Leading Dimension | Row-major에서 행 간격 = 열 수 (패딩 없을 때) |
| 총 FLOP | 2 * M * N * K |
| FMA와 FLOP | FMA 1회 = 2 FLOP (곱셈 + 덧셈) |
| 최소 메모리 트래픽 | sizeof(float) * (M*K + K*N + 2*M*N) |
| 산술 강도 | AI = FLOP / Bytes (정사각일 때 n/8) |
| 루프라인 모델 | 성능 <= min(피크연산, 피크대역폭 * AI) |
| 릿지 포인트 | 피크연산 / 피크대역폭 |
| SGEMM 최적화 적합성 | O(n^3) 연산 vs O(n^2) 데이터 -> AI가 n과 함께 증가 |

**기억해야 할 세 가지:**

1. **2MNK**: SGEMM의 FLOP 수는 항상 2 * M * N * K이다.
2. **n/8**: 정사각 행렬에서 이론적 산술 강도는 n/8 FLOP/byte이다.
3. **루프라인**: 최적화란 유효 산술 강도를 높여 루프라인 다이어그램에서 커널을 오른쪽으로 이동시키는 것이다.

---

## 8. 퀴즈

### 문제 1 (기억)

SGEMM의 총 FLOP 수를 M, N, K로 나타내는 공식을 쓰시오.

<details>
<summary>정답</summary>

```
총 FLOP = 2 * M * N * K
```

각 출력 원소에 K번의 FMA가 필요하고, FMA 하나가 2 FLOP이며, 출력 원소가 M*N개이므로 2*M*N*K이다.

</details>

---

### 문제 2 (적용)

M=2048, N=2048, K=2048일 때 총 FLOP 수를 GFLOP 단위로 계산하시오.

<details>
<summary>정답</summary>

```
총 FLOP = 2 * 2048 * 2048 * 2048
       = 2 * 2048^3
       = 2 * 8,589,934,592
       = 17,179,869,184
       = 약 17.18 GFLOP
```

</details>

---

### 문제 3 (이해)

"산술 강도가 높다"는 것은 커널의 동작 특성에 대해 무엇을 의미하는지 설명하시오.

<details>
<summary>정답</summary>

산술 강도가 높다는 것은 메모리에서 전송한 바이트 대비 많은 연산을 수행한다는 의미이다. 구체적으로:

- 데이터를 한 번 로드하면 여러 번 재사용하여 많은 연산에 활용한다.
- 메모리 대역폭보다는 연산 유닛의 처리량이 성능의 병목이 될 가능성이 높다.
- 루프라인 모델에서 릿지 포인트 오른쪽에 위치하여 연산 바운드 영역에 해당한다.

반대로 산술 강도가 낮으면 데이터를 로드해서 적은 연산만 하고 버리므로 메모리 대역폭이 병목이 된다.

</details>

---

### 문제 4 (적용)

M=N=K=4096일 때 커널 실행 시간이 2.0ms라면, 달성된 GFLOP/s는 얼마인가?

<details>
<summary>정답</summary>

```
총 FLOP = 2 * 4096^3 = 137,438,953,472

GFLOP/s = 137,438,953,472 / (0.002 * 10^9)
        = 137,438,953,472 / 2,000,000
        = 68,719.5 GFLOP/s
        = 약 68,720 GFLOP/s
```

참고: 이 값은 단일 GPU의 이론적 피크(예: A100에서 약 19,500 GFLOP/s)를 훨씬 초과하므로, 실행 시간 2.0ms는 이 크기의 행렬에 대해 비현실적이다. 현실적인 실행 시간은 최소 약 7ms(피크의 100%) 이상이어야 한다.

</details>

---

### 문제 5 (분석)

루프라인 모델에서 릿지 포인트(ridge point)를 결정하는 두 가지 하드웨어 요소는 무엇이며, 릿지 포인트가 높은 GPU에서 SGEMM 최적화 시 어떤 의미가 있는가?

<details>
<summary>정답</summary>

릿지 포인트를 결정하는 두 가지 요소는 다음과 같다.

1. **피크 연산 처리량** (GFLOP/s): SM 수, FP32 코어 수, 클럭 주파수로 결정
2. **피크 메모리 대역폭** (GB/s): 메모리 버스 폭, 메모리 클럭으로 결정

```
릿지 포인트 = 피크 연산 처리량 / 피크 메모리 대역폭
```

릿지 포인트가 높은 GPU(즉, 연산 대비 대역폭이 상대적으로 낮은 GPU)에서는:

- 커널이 연산 바운드 영역에 도달하려면 더 높은 산술 강도가 필요하다.
- 더 큰 타일 크기, 더 적극적인 데이터 재사용이 요구된다.
- 같은 커널이라도 이런 GPU에서는 메모리 바운드에 머물 수 있다.

따라서 릿지 포인트가 높을수록 메모리 최적화(코얼레싱, 타일링, 레지스터 블로킹)의 중요성이 커진다.

</details>

---

## 9. 다음 단계 미리보기

다음 모듈 4에서는 **Level 0 Naive 구현**을 다룬다.

이 모듈에서 배운 수학적 개념을 실제 CUDA 커널에 적용하는 첫 번째 단계이다. Naive 커널(`src/kernels/sgemm_naive.cu`)은 각 스레드가 C의 원소 하나를 계산하는 가장 단순한 구현으로, 다음을 분석할 것이다.

- 각 스레드가 수행하는 `row * lda + k` 인덱싱이 어떤 메모리 접근 패턴을 만드는지
- 실제 메모리 트래픽이 `sgemm_min_bytes()`의 이론치와 얼마나 차이가 나는지
- 루프라인 모델에서 Naive 커널이 어디에 위치하는지
- 왜 cuBLAS 대비 1~5% 수준의 성능만 달성하는지

Naive 커널의 한계를 정확히 이해해야 이후 모듈(Level 1~5)에서의 각 최적화가 "무엇을 해결하는가"를 명확히 파악할 수 있다.
