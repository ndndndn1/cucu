# 모듈 10: 종합 성능분석 및 프로파일링

---

## 1. 학습 목표

이 모듈을 완료하면 다음을 할 수 있다.

| 목표 | Bloom 수준 |
|------|-----------|
| Nsight Compute의 핵심 프로파일링 명령어를 사용할 수 있다 | 적용(Apply) |
| SOL(Speed of Light) 차트를 읽고 커널 상태를 분류할 수 있다 | 분석(Analyze) |
| Warp Stall 원인을 해석하고 개선 방향을 판단할 수 있다 | 분석(Analyze) |
| 루프라인 모델에 6개 커널을 배치하고 병목을 식별할 수 있다 | 평가(Evaluate) |
| 프로파일링 데이터로부터 다음 최적화 단계를 결정할 수 있다 | 평가(Evaluate) |

---

## 2. 사전 복습

다음 3개 문항을 **보지 않고** 답한 뒤 모듈 8-9의 내용과 대조해 본다.

1. 더블 버퍼링이 해결하는 핵심 문제는 무엇이며, 공유 메모리 사용량은 단일 버퍼 대비 어떻게 변하는가?
2. `cp.async`가 레지스터를 우회하는 것이 점유율에 어떤 이점을 주는가?
3. 산술 강도(Arithmetic Intensity)의 정의와 단위는?

<details>
<summary>정답 확인</summary>

1. 글로벌 메모리 로드 레이턴시(400+ 사이클)를 연산과 중첩하는 것이 핵심이다. 현재 버퍼로 연산하면서 다음 버퍼로 데이터를 로드한다. 공유 메모리 사용량은 2배(`As[2][BM][BK+1]`)로 증가한다.
2. `cp.async`는 글로벌 메모리에서 공유 메모리로 직접 복사하므로 중간 레지스터가 필요 없다. 레지스터 사용량 감소는 SM당 더 많은 워프를 동시 실행할 수 있게 하여 점유율을 높인다.
3. 전송된 바이트당 수행하는 부동소수점 연산 수. 단위는 FLOP/byte이다. `산술 강도 = FLOP / 전송 바이트`.

</details>

---

## 3. 개념 설명

### 3.1 왜 프로파일링인가?

**Concrete (구체적 비유)**

의사가 환자를 진단할 때 "어딘가 아프다"는 증상만으로는 치료 방향을 정할 수 없다. 혈압, 혈액 검사, CT 촬영 등 **정량적 데이터**가 있어야 정확한 진단과 처방이 가능하다. GPU 커널 성능 분석도 마찬가지이다. "느리다"는 관찰만으로는 어디를 최적화해야 하는지 알 수 없다. Nsight Compute가 바로 GPU 커널의 "CT 스캐너"이다.

**Representational (표상적 -- 워크플로)**

```
┌──────────────┐     ┌───────────────┐     ┌───────────────┐     ┌──────────────┐
│  커널 실행   │ --> │  Nsight       │ --> │  데이터 해석  │ --> │  최적화 결정 │
│              │     │  Compute      │     │               │     │              │
│  ncu로       │     │  .ncu-rep     │     │  SOL, Stall,  │     │  다음 레벨   │
│  프로파일    │     │  리포트 생성  │     │  Memory 분석  │     │  또는 튜닝   │
└──────────────┘     └───────────────┘     └───────────────┘     └──────────────┘
```

**Abstract (추상적)**

프로파일링은 **측정 → 분석 → 결정**의 반복 과정이다. 핵심 질문은 세 가지이다:

1. **어디서 시간을 보내는가?** (SOL 분석)
2. **왜 시간을 보내는가?** (Stall 분석)
3. **다음에 무엇을 할 것인가?** (의사결정 트리)

### 3.2 Speed of Light (SOL) 분석

SOL은 현재 커널이 하드웨어 이론적 최대 성능의 몇 %를 달성하고 있는지를 보여준다. 두 가지 축이 있다.

| 메트릭 | 의미 | 확인 위치 |
|--------|------|-----------|
| **SM Throughput (%)** | 연산 유닛(FMA, ALU 등) 활용도 | SOL > Compute |
| **Memory Throughput (%)** | 메모리 대역폭(DRAM, L2) 활용도 | SOL > Memory |

**SOL 해석 매트릭스:**

```
                Memory Throughput
                Low              High
SM        ┌────────────────┬────────────────┐
Throughput│                │                │
High      │  Compute       │  Balanced      │
          │  Bound         │  (최적 상태)   │
          │  → 산술 최적화 │  → 미세 조정   │
          ├────────────────┼────────────────┤
Low       │  Latency       │  Memory        │
          │  Bound         │  Bound         │
          │  → 파이프라인  │  → 데이터 재사용│
          │    최적화 필요 │    증가 필요   │
          └────────────────┴────────────────┘
```

우리 6개 커널의 예상 SOL 위치:

| 커널 | SM (%) | Memory (%) | 상태 |
|------|--------|------------|------|
| Level 0: Naive | ~5 | ~20 | Latency Bound |
| Level 1: Coalesced | ~10 | ~50 | Memory Bound |
| Level 2: Tiled | ~30 | ~60 | Memory Bound |
| Level 3: Register Blocking | ~60 | ~70 | Balanced |
| Level 4: Double Buffer | ~75 | ~80 | Good Balance |
| Level 5: Async Copy | ~85 | ~85 | Optimal |

참조: `docs/ANALYSIS_GUIDE.md:41-48`

### 3.3 Warp Stall 분석

워프가 명령어를 발행(issue)하지 못하고 대기하는 이유를 **스톨(Stall)**이라 한다. Nsight Compute의 **Warp State Statistics** 섹션에서 확인할 수 있다.

| 스톨 원인 | 의미 | 해결 방향 |
|-----------|------|-----------|
| **Long Scoreboard** | 글로벌 메모리 로드 완료 대기 | 프리페치, 더블 버퍼링, `cp.async` |
| **Wait** | 동기화 대기 (`__syncthreads()`, `cp.async.wait`) | 파이프라인 깊이 증가, 동기화 위치 최적화 |
| **Math Pipe Throttle** | 연산 파이프라인 포화 | **최적 상태!** 연산 유닛을 최대로 활용 중 |
| **LG Throttle** | L1/공유 메모리 대역폭 병목 | 뱅크 충돌 해결, 벡터화 적용 |

참조: `docs/ANALYSIS_GUIDE.md:50-74`

**6단계 최적화에 따른 스톨 변화:**

```
Level 0 (Naive):
  Long Scoreboard: ████████████████████████████████████████ 80%+
  Math Pipe:       ██ 5%

Level 2 (Tiled):
  Long Scoreboard: ████████████████████████ 50%
  Math Pipe:       ████████ 15%
  Wait:            ██████ 10%

Level 4 (Double Buffer):
  Long Scoreboard: ██████████ 20%
  Math Pipe:       ██████████████████████████████ 30%
  Wait:            ████████████ 15%

Level 5 (Async Copy):
  Long Scoreboard: ████ 10%
  Math Pipe:       ██████████████████████████████████ 40%+
  Wait:            ██████████ 12%
```

Long Scoreboard가 줄어들고 Math Pipe Throttle이 증가하는 것은 **메모리 레이턴시를 성공적으로 숨기고 연산 유닛을 더 활발히 사용**하고 있다는 뜻이다.

### 3.4 루프라인 모델 (Roofline Model)

루프라인 모델은 커널의 **산술 강도**(FLOP/byte)와 **달성 성능**(GFLOP/s)을 하나의 그래프에 표현하여, 커널이 연산 바운드인지 메모리 바운드인지 직관적으로 보여준다.

**모델 구조:**

```
달성 성능     컴퓨트 루프라인 (피크 GFLOP/s)
(GFLOP/s)    ─────────────────────────────────── ← 연산 피크
  ↑         /
  │        /
  │       /  ← 메모리 대역폭 경사면 (기울기 = 피크 BW)
  │      /
  │     /
  │    /
  │   /
  │  /
  │ /
  └──────────────────────────────────────────── →
            산술 강도 (FLOP/byte)

  루프라인 = min(피크 GFLOP/s, 산술 강도 × 피크 대역폭)
```

**변곡점(Ridge Point)**: 연산 바운드와 메모리 바운드의 경계

```
변곡점 산술 강도 = 피크 GFLOP/s / 피크 대역폭 (GB/s)
```

예시 (A100): `19,500 GFLOP/s / 2,039 GB/s ≈ 9.6 FLOP/byte`

**6개 커널의 루프라인 위치:**

```
성능
(GFLOP/s)
19500 ┤─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ 피크 컴퓨트
      │                                    ★ L5 (Async)
16000 ┤                                  ★ L4 (DblBuf)
      │
13000 ┤                              ★ L3 (RegBlock)
      │
10000 ┤
      │                 /
 7000 ┤               /
      │             /
 4000 ┤           /
      │     ★ L2 (Tiled)
 2000 ┤   /
      │ ★ L1 (Coalesced)
  500 ┤★ L0 (Naive)
      └──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──→
        0.25 0.5 1  2  4  6  8 10 12 14 16
                  산술 강도 (FLOP/byte)
```

| 커널 | 산술 강도 (FLOP/byte) | 예상 GFLOP/s | 위치 |
|------|----------------------|-------------|------|
| Level 0: Naive | 0.25 | ~500 | 경사면 아래 (레이턴시 바운드) |
| Level 1: Coalesced | 0.5 | ~1,000 | 경사면 위 (메모리 바운드) |
| Level 2: Tiled | ~2.0 | ~4,000 | 경사면 위 (메모리 바운드) |
| Level 3: Register Blocking | ~8.0 | ~13,000 | 변곡점 부근 |
| Level 4: Double Buffer | ~8.0 | ~16,000 | 변곡점 위 (연산 바운드 진입) |
| Level 5: Async Copy | ~8.0 | ~17,000+ | 피크 근처 |

Level 3-5는 산술 강도가 동일하지만(같은 레지스터 블로킹 구조), 레이턴시 은닉 기법의 차이로 실제 달성 성능이 달라진다.

### 3.5 메모리 효율성 분석

Nsight Compute에서 확인할 수 있는 핵심 메모리 메트릭:

**글로벌 메모리 코얼레싱:**

```
확인 위치: Memory Workload Analysis > L1/TEX Cache > Sectors/Request

이상적인 값: 1.0 (완벽한 코얼레싱)
문제가 있는 값: >4.0 (많은 트랜잭션 필요)
```

참조: `docs/ANALYSIS_GUIDE.md:78-83`

**SASS 명령어 패턴:**

```
좋은 패턴:
- LDG.E.128  : 128-bit 글로벌 로드 (float4)  → Level 1+
- LDGSTS     : 글로벌→공유 직접 복사 (cp.async) → Level 5

나쁜 패턴:
- LDG.E     : 32-bit 로드만 사용 → Level 0
- LDG + STS : 레지스터 경유 (cp.async 미작동) → 컴파일러 문제
```

참조: `docs/ANALYSIS_GUIDE.md:86-115`

**뱅크 충돌 확인:**

```
확인 위치: Memory Workload Analysis > L1/TEX Cache >
           Wavefronts Shared Excessive

이상적인 값: 1.0
문제가 있는 값: >1.0 (뱅크 충돌 발생)
```

### 3.6 레지스터 압력과 점유율

```
확인 위치: Launch Statistics > Registers Per Thread

권장 범위: 64-128 레지스터/스레드
경고 임계: 255 초과 시 스필링 발생
```

**레지스터 스필링 탐지 (SASS):**

| 명령어 | 의미 | 성능 영향 |
|--------|------|-----------|
| `LDL` | 로컬 메모리에서 레지스터로 로드 | 글로벌 메모리 접근과 동일한 레이턴시 |
| `STL` | 레지스터에서 로컬 메모리로 저장 | 글로벌 메모리 접근과 동일한 레이턴시 |

이 명령어가 보이면 레지스터가 부족하여 로컬 메모리(실제로는 글로벌 메모리)를 사용하고 있다는 뜻이다. `__launch_bounds__` 지정 또는 타일 크기 축소로 해결한다.

참조: `docs/ANALYSIS_GUIDE.md:117-139`

**점유율에 대한 흔한 오해:**

```
오해: 높은 점유율 = 높은 성능
현실: 레지스터 블로킹 커널은 25-50% 점유율로도 최고 성능 달성 가능

이유:
- ILP(Instruction-Level Parallelism)가 높으면 적은 워프로도 파이프라인을 채울 수 있다
- 레지스터를 많이 쓰면 점유율은 낮아지지만 메모리 접근은 줄어든다
- 메모리 바운드 커널은 높은 점유율이 유리하지만,
  컴퓨트 바운드 커널은 점유율보다 ILP가 중요하다
```

참조: `docs/ANALYSIS_GUIDE.md:141-163`

---

## 4. 코드 분석

### 4.1 벤치마크 러너의 성능 메트릭 계산

소스 파일: `src/benchmark/benchmark_runner.cpp`

벤치마크 러너는 커널 실행 시간으로부터 핵심 성능 메트릭을 계산한다.

```cpp
// 피크 성능 추정 (src/benchmark/benchmark_runner.cpp:88-102)
int fp32_cores_per_sm = 64;  // 보수적 추정
if (info.compute_major >= 8) {
    fp32_cores_per_sm = 64;  // Ampere
} else if (info.compute_major >= 7) {
    fp32_cores_per_sm = 64;  // Volta/Turing
}

double clock_ghz = 1.5;  // 보수적 클럭 추정
peak_tflops_ = info.sm_count * fp32_cores_per_sm * clock_ghz * 2 / 1000.0;
```

| 항목 | 수식 | 설명 |
|------|------|------|
| 피크 TFLOPS | `SM수 × 코어/SM × 클럭(GHz) × 2 / 1000` | FMA가 곱셈+덧셈 2 FLOP이므로 ×2 |
| 달성 GFLOP/s | `2MNK / (실행시간_ms × 10⁶)` | SGEMM FLOP = 2MNK |
| 메모리 대역폭 | `최소전송바이트 / (실행시간_ms × 10⁶)` | 최소 바이트 = (M×K + K×N + M×N) × 4 |
| 피크 대비 효율 | `달성 GFLOP/s / 피크 GFLOP/s × 100` | 하드웨어 활용률 |
| cuBLAS 대비 효율 | `달성 GFLOP/s / cuBLAS GFLOP/s × 100` | 실용적 목표 지표 |

```cpp
// 성능 메트릭 계산 (src/benchmark/benchmark_runner.cpp:239-249)
double flops = sgemm_flops(M, N, K);          // = 2 * M * N * K
result.gflops = flops / (result.median_ms * 1e6);

double bytes = sgemm_min_bytes(M, N, K);      // = (M*K + K*N + M*N) * 4
result.memory_bandwidth_gb = bytes / (result.median_ms * 1e6);

result.efficiency_vs_peak = result.gflops / (peak_tflops_ * 1000);
```

**중앙값(median)을 사용하는 이유:** 평균은 극단적 이상치(GPU 클럭 스로틀링, OS 인터럽트 등)에 민감하다. 중앙값은 이러한 노이즈에 강건하여 커널의 "일반적인" 성능을 더 정확하게 반영한다.

### 4.2 Nsight Compute 프로파일링 실행

소스 파일: `docs/ANALYSIS_GUIDE.md:8-19`

```bash
# 기본 프로파일링: 모든 메트릭 수집
ncu --set full -o sgemm_profile ./sgemm_benchmark -m 4096 -n 4096 -k 4096 -l 5

# 특정 메트릭만 수집 (빠른 확인)
ncu --metrics sm__throughput.avg_pct_of_peak_sustained_elapsed,\
dram__throughput.avg_pct_of_peak_sustained_elapsed \
-o sgemm_profile ./sgemm_benchmark

# SASS 소스 분석 포함
ncu --set full --section SourceCounters -o sgemm_sass ./sgemm_benchmark
```

| 옵션 | 의미 |
|------|------|
| `--set full` | 모든 메트릭 섹션 수집 |
| `-o` | 출력 리포트 파일명 (.ncu-rep 확장자 자동 추가) |
| `--metrics` | 특정 메트릭만 수집 (전체 프로파일보다 빠름) |
| `--section SourceCounters` | SASS 명령어별 실행 카운터 포함 |

### 4.3 실전 분석 체크리스트

각 최적화 단계에서 Nsight Compute로 확인해야 할 항목:

참조: `docs/ANALYSIS_GUIDE.md:165-191`

**Phase 1: Naive → Coalesced**
- [ ] `LDG.E`가 `LDG.E.128`로 변경되었는가?
- [ ] Global Load Efficiency > 80%?
- [ ] Sectors/Request ≈ 1.0?

**Phase 2: Coalesced → Tiled**
- [ ] 공유 메모리 사용량이 예상대로인가?
- [ ] Wavefronts Shared Excessive ≈ 1.0? (뱅크 충돌 없음)
- [ ] Long Scoreboard가 감소했는가?

**Phase 3: Tiled → Register Blocking**
- [ ] FMA 파이프라인 활용도 증가?
- [ ] 레지스터 사용량 ≤ 255? (스필링 방지)
- [ ] SASS에서 `LDL`/`STL` 없는가?

**Phase 4: Register Blocking → Double Buffer**
- [ ] Long Scoreboard 감소?
- [ ] 로드와 연산이 오버랩되는가?
- [ ] 공유 메모리 사용량이 2배가 되었는가?

**Phase 5: Double Buffer → Async Copy**
- [ ] SASS에서 `LDGSTS` 명령어 생성?
- [ ] `LDG` + `STS` 분리 패턴이 제거되었는가?
- [ ] Wait 스톨이 적절한 수준인가?

---

## 5. 왜 이것이 작동하는가?

### Q1. 왜 Long Scoreboard가 가장 중요한 스톨 지표인가?

Long Scoreboard는 글로벌 메모리 로드가 완료되기를 기다리는 워프의 비율이다. 글로벌 메모리 접근 레이턴시는 400-800 사이클로, FMA 명령어(4 사이클)의 100-200배에 달한다. 이 스톨이 높다는 것은 GPU의 연산 유닛이 데이터를 기다리며 유휴 상태라는 뜻이다.

Level 0에서 Long Scoreboard이 80%+인 것은 거의 모든 시간을 메모리 대기에 보낸다는 뜻이며, Level 5에서 10%로 감소한 것은 `cp.async` 파이프라인이 레이턴시를 거의 완벽하게 은닉하고 있다는 뜻이다.

### Q2. 왜 SM SOL과 Memory SOL이 동시에 낮을 수 있는가?

두 지표가 동시에 낮은 "레이턴시 바운드" 상태는 직관에 반한다. 연산도 안 하고 메모리도 안 쓰면 GPU가 뭘 하고 있는가?

답: **기다리고 있다.** 메모리 요청을 보내긴 했지만 도착하지 않은 상태에서, 다른 할 일이 없어 멈춰 있다. 메모리 대역폭을 포화시키려면 충분히 많은 메모리 요청이 동시에 비행(in-flight) 중이어야 하는데, 나이브 커널은 요청-대기-연산-요청의 직렬 패턴이므로 동시 비행 요청 수가 적다.

타일링과 프리페칭은 이 "동시 비행 요청 수"를 늘려 메모리 대역폭을 더 활용하게 만든다.

### Q3. 왜 점유율이 높다고 항상 성능이 좋은 것은 아닌가?

점유율은 SM에서 동시 실행되는 워프 수의 비율이다. 높은 점유율은 많은 워프가 레이턴시를 숨길 수 있다는 잠재력을 의미하지만, 이미 레이턴시가 충분히 숨겨진 경우(Level 3-5의 레지스터 블로킹), 점유율을 더 올리는 것보다 **ILP(명령어 수준 병렬성)**을 높이는 것이 더 효과적이다.

레지스터를 많이 사용할수록(점유율↓) 글로벌 메모리 접근은 줄어든다(성능↑). 이것이 Level 3에서 점유율 25-50%로도 Level 2(점유율 50-75%)보다 훨씬 빠른 이유이다.

### Q4. cuBLAS와 100% 동일한 성능에 도달하지 못하는 이유는?

우리 구현이 85-95%에 그치는 세 가지 이유:

1. **텐서 코어 미사용**: cuBLAS는 Ampere 이상에서 FP32도 TF32 텐서 코어를 활용할 수 있다. 텐서 코어는 일반 FMA 대비 8-16배 처리량을 제공한다.
2. **아키텍처별 튜닝 부재**: cuBLAS는 GPU 아키텍처(SM 수, 캐시 크기, 클럭)에 맞춰 타일 크기, 파이프라인 깊이, 워프 스케줄링을 자동 선택한다.
3. **마이크로 아키텍처 최적화**: 레지스터 캐시 활용, L2 분할 정책, TMA(Tensor Memory Accelerator) 등 문서화되지 않은 하드웨어 기능을 활용한다.

참조: `docs/ANALYSIS_GUIDE.md:208-219`

---

## 6. 시뮬레이션 10: 모의 프로파일 데이터 해석

### 목표

실제 Nsight Compute 리포트 없이도, 제시된 프로파일 데이터를 읽고 커널의 문제점과 개선 방향을 판단하는 연습을 한다.

### 데이터

아래는 4096x4096 SGEMM을 실행한 가상의 Nsight Compute 리포트이다.

**커널 A 프로파일:**

```
┌──────────────────────────────────────────────────┐
│ Kernel: mystery_kernel_A                         │
├──────────────────────────────────────────────────┤
│ SOL                                              │
│   SM Throughput:        12.3%                    │
│   Memory Throughput:    54.7%                    │
│                                                  │
│ Warp Stall Reasons (Top 3)                       │
│   Long Scoreboard:      62.1%                    │
│   Wait:                  8.3%                    │
│   Not Selected:         14.2%                    │
│                                                  │
│ Memory                                           │
│   Sectors/Request:       1.0                     │
│   Shared Memory:         8 KB / block            │
│   Wavefronts Shared:     1.0                     │
│                                                  │
│ Launch                                           │
│   Registers/Thread:      32                      │
│   Occupancy:             62.5%                   │
│   Block Size:            256                     │
│                                                  │
│ SASS (top instructions)                          │
│   LDG.E.128             23.1%                    │
│   FFMA                  31.2%                    │
│   STS.128                8.4%                    │
│                                                  │
│ Performance: 3,847 GFLOP/s                       │
└──────────────────────────────────────────────────┘
```

**커널 B 프로파일:**

```
┌──────────────────────────────────────────────────┐
│ Kernel: mystery_kernel_B                         │
├──────────────────────────────────────────────────┤
│ SOL                                              │
│   SM Throughput:        71.8%                    │
│   Memory Throughput:    78.3%                    │
│                                                  │
│ Warp Stall Reasons (Top 3)                       │
│   Math Pipe Throttle:   34.5%                    │
│   Long Scoreboard:      18.7%                    │
│   Wait:                 22.1%                    │
│                                                  │
│ Memory                                           │
│   Sectors/Request:       1.0                     │
│   Shared Memory:         32 KB / block           │
│   Wavefronts Shared:     1.0                     │
│                                                  │
│ Launch                                           │
│   Registers/Thread:      96                      │
│   Occupancy:             33.3%                   │
│   Block Size:            256                     │
│                                                  │
│ SASS (top instructions)                          │
│   LDG.E.128             11.2%                    │
│   FFMA                  52.8%                    │
│   STS.128                4.1%                    │
│   LDS.128                7.3%                    │
│                                                  │
│ Performance: 14,520 GFLOP/s                      │
└──────────────────────────────────────────────────┘
```

**커널 C 프로파일:**

```
┌──────────────────────────────────────────────────┐
│ Kernel: mystery_kernel_C                         │
├──────────────────────────────────────────────────┤
│ SOL                                              │
│   SM Throughput:         4.2%                    │
│   Memory Throughput:    18.5%                    │
│                                                  │
│ Warp Stall Reasons (Top 3)                       │
│   Long Scoreboard:      84.3%                    │
│   Not Selected:          6.1%                    │
│   Wait:                  2.4%                    │
│                                                  │
│ Memory                                           │
│   Sectors/Request:       4.2                     │
│   Shared Memory:         0 KB / block            │
│   Wavefronts Shared:     N/A                     │
│                                                  │
│ Launch                                           │
│   Registers/Thread:      16                      │
│   Occupancy:            100.0%                   │
│   Block Size:            256                     │
│                                                  │
│ SASS (top instructions)                          │
│   LDG.E                 45.2%                    │
│   FFMA                  18.3%                    │
│   IADD3                 12.1%                    │
│                                                  │
│ Performance: 487 GFLOP/s                         │
└──────────────────────────────────────────────────┘
```

### 과제

각 커널에 대해 다음을 분석하시오:

**Step 1**: 이 커널은 우리의 6개 레벨(Level 0-5) 중 어느 것에 해당하는가? 판별 근거를 3가지 이상 제시하시오.

**Step 2**: 현재 커널의 주요 병목은 무엇인가? SOL 매트릭스의 4가지 상태 중 어디에 해당하는가?

**Step 3**: 이 커널의 다음 최적화 방향은 무엇인가? 성능 튜닝 의사결정 트리를 적용하여 설명하시오.

### 분석 가이드

**의사결정 트리** (참조: `docs/ANALYSIS_GUIDE.md:194-206`):

```
SOL에서 SM Throughput이 낮은가?
├─ Yes → Memory가 높은가?
│        ├─ Yes → 데이터 재사용 증가 (타일링, 레지스터 블로킹)
│        └─ No → 레이턴시 숨기기 (프리페치, 더블 버퍼링, cp.async)
└─ No → 최적 상태, micro-optimization 검토

Stall 원인이 Long Scoreboard인가?
├─ Yes → 프리페치/파이프라이닝 개선
└─ No → Wait인가?
         ├─ Yes → 동기화 최적화
         └─ No → Math Pipe Throttle이면 최적!
```

<details>
<summary>정답 확인</summary>

### 커널 A 분석

**Step 1: Level 2 (공유 메모리 타일링)**
- 공유 메모리 8 KB 사용 (타일링 활성화)
- `LDG.E.128` + `STS.128` 패턴 (코얼레싱된 로드 → 공유 메모리 저장)
- 레지스터 32개/스레드 (레지스터 블로킹 미적용)
- 점유율 62.5% (적당히 높음, 레지스터 블로킹이면 더 낮을 것)
- 3,847 GFLOP/s (cuBLAS의 약 20-25%)

**Step 2: Memory Bound**
- SM 12.3% (낮음), Memory 54.7% (중간-높음) → Memory Bound
- Long Scoreboard 62.1%로 메모리 로드 대기가 지배적

**Step 3: 레지스터 블로킹 도입**
- 의사결정 트리: SM 낮음 → Memory 높음 → "데이터 재사용 증가"
- 스레드당 여러 C 원소를 레지스터에 보관하여 산술 강도를 높인다
- 이것이 Level 2 → Level 3 전환이다

### 커널 B 분석

**Step 1: Level 4 (더블 버퍼링) 또는 Level 3 후기 최적화**
- 공유 메모리 32 KB (이중 버퍼 = 16 KB × 2)
- 레지스터 96개/스레드 (레지스터 블로킹 활성화)
- 점유율 33.3% (레지스터 사용량에 의한 제한)
- Math Pipe Throttle 34.5% (연산 파이프라인 활발)
- FFMA 비중 52.8% (연산 집약적)
- 14,520 GFLOP/s (cuBLAS의 약 75%)

**Step 2: Balanced (Good Balance)**
- SM 71.8%, Memory 78.3% → 두 리소스 모두 잘 활용 중
- Math Pipe Throttle이 1위 스톨이므로 연산 포화에 가까움

**Step 3: cp.async 도입**
- Long Scoreboard가 여전히 18.7% → 레이턴시 은닉 여지 있음
- Wait 22.1% → 동기화 오버헤드 있음
- `cp.async`로 레지스터 우회 + 트리플 버퍼링으로 두 문제 동시 개선
- 이것이 Level 4 → Level 5 전환이다

### 커널 C 분석

**Step 1: Level 0 (나이브)**
- 공유 메모리 미사용 (0 KB)
- `LDG.E` (32비트 로드, 벡터화 없음)
- Sectors/Request 4.2 (코얼레싱 불량)
- 레지스터 16개/스레드 (최소 사용)
- 점유율 100% (리소스 제한 없음)
- 487 GFLOP/s (cuBLAS의 ~2.5%)

**Step 2: Latency Bound**
- SM 4.2% (매우 낮음), Memory 18.5% (낮음) → Latency Bound
- Long Scoreboard 84.3%로 거의 모든 시간이 메모리 대기

**Step 3: 메모리 코얼레싱 + float4 벡터화**
- 의사결정 트리: SM 낮음 → Memory 낮음 → "레이턴시 숨기기"
- 그러나 더 근본적으로, Sectors/Request 4.2가 먼저 해결되어야 함
- float4 벡터화로 `LDG.E.128` 생성 → 코얼레싱 개선 → 메모리 대역폭 활용도 증가
- 이것이 Level 0 → Level 1 전환이다

</details>

---

## 7. 핵심 정리

- **Nsight Compute**는 GPU 커널의 핵심 프로파일러이다. `ncu --set full -o <output> <program>`으로 실행한다.
- **SOL 분석**에서 SM/Memory Throughput의 조합으로 4가지 상태를 분류한다:
  - Latency Bound (둘 다 낮음) → 파이프라인 최적화
  - Memory Bound (SM 낮음, Memory 높음) → 데이터 재사용 증가
  - Compute Bound (SM 높음) → 최적 상태
  - Balanced (둘 다 높음) → 미세 조정
- **Warp Stall 분석**에서 Long Scoreboard 감소, Math Pipe Throttle 증가가 최적화 성공의 지표이다.
- **루프라인 모델**에서 6개 커널은 경사면 아래(Level 0)에서 피크 근처(Level 5)로 이동한다.
- **의사결정 트리**를 따라 프로파일 데이터로부터 다음 최적화 단계를 체계적으로 결정한다.
- cuBLAS 대비 85-95% 달성 후 남은 차이는 텐서 코어, 아키텍처별 튜닝, 마이크로 최적화에 기인한다.

---

## 8. 퀴즈

### Q1. (Remember)
Nsight Compute에서 SOL 분석의 두 가지 핵심 축은 무엇인가?

<details>
<summary>정답</summary>
SM Throughput (%)과 Memory Throughput (%)이다. SM Throughput은 연산 유닛 활용도를, Memory Throughput은 메모리 대역폭 활용도를 나타낸다.
</details>

### Q2. (Understand)
"Latency Bound" 상태가 SM과 Memory 모두 낮은 이유를 자신의 말로 설명하시오.

<details>
<summary>정답</summary>
메모리 요청을 보낸 뒤 데이터 도착을 기다리는 동안 연산도 하지 못하고 다른 메모리 요청도 보내지 못하는 상태이다. 동시에 비행 중인(in-flight) 메모리 요청이 적어 메모리 대역폭을 포화시키지 못하고(Memory SOL 낮음), 대기 중에 연산 유닛도 놀고 있다(SM SOL 낮음). 요청-대기-연산이 직렬로 일어나므로 두 리소스 모두 비효율적이다.
</details>

### Q3. (Apply)
피크 19,500 GFLOP/s, 피크 대역폭 2,039 GB/s인 GPU에서 루프라인 모델의 변곡점(ridge point) 산술 강도를 계산하시오.

<details>
<summary>정답</summary>

```
변곡점 산술 강도 = 피크 GFLOP/s / 피크 대역폭
                = 19,500 / 2,039
                ≈ 9.56 FLOP/byte
```

산술 강도가 9.56 FLOP/byte 미만인 커널은 메모리 바운드, 이상인 커널은 컴퓨트 바운드이다.
</details>

### Q4. (Apply)
M=N=K=4096 SGEMM이 3.2ms에 완료되었다. 달성 GFLOP/s를 계산하시오.

<details>
<summary>정답</summary>

```
FLOP = 2 × M × N × K = 2 × 4096 × 4096 × 4096 = 274,877,906,944 ≈ 2.749 × 10^11
달성 GFLOP/s = FLOP / (시간_ms × 10^6)
            = 2.749 × 10^11 / (3.2 × 10^6)
            = 85,899 × 10^0
            ≈ 85,899 MFLOP/s
            = 85.9 GFLOP/s

잠깐, 다시 계산:
FLOP = 2 × 4096³ = 2 × 68,719,476,736 = 137,438,953,472
달성 GFLOP/s = 137,438,953,472 / (3.2 × 10⁻³ × 10⁹)
            = 137,438,953,472 / 3,200,000
            ≈ 42,950 GFLOP/s

아니다, 단위를 정리하면:
GFLOP/s = (2 × 4096³) / (3.2ms × 10⁶)
        = 137,438,953,472 / 3,200,000
        ≈ 42,950 GFLOP/s
```

**정답: 약 42,950 GFLOP/s**

> 참고: `sgemm_flops()` 함수(`include/sgemm_kernels.hpp:195-198`)는 `2.0 * M * N * K`를 반환한다.
</details>

### Q5. (Analyze)
SASS에서 `LDGSTS` 명령어가 보이지 않고 `LDG` + `STS` 패턴이 보인다면 어떤 문제가 있는가?

<details>
<summary>정답</summary>
`cp.async`가 의도대로 작동하지 않고 있다. `LDGSTS`는 `cp.async`의 하드웨어 구현으로, 글로벌 메모리에서 공유 메모리로 레지스터를 거치지 않고 직접 복사한다. `LDG` + `STS` 패턴은 데이터가 레지스터를 경유하므로:

1. 레지스터 사용량이 증가하여 점유율이 낮아진다.
2. cp.async의 비동기 파이프라인 이점을 활용하지 못한다.
3. 메모리 복사와 연산의 오버랩이 불완전해진다.

원인으로는 컴파일러 버전 문제, 정렬 요구사항 미충족, `cp.async` PTX 인라인 어셈블리 오류 등이 있을 수 있다.
</details>

### Q6. (Analyze)
커널의 Warp Stall에서 Long Scoreboard가 60%, Wait가 25%일 때, 이 커널의 상태와 개선 방향을 분석하시오.

<details>
<summary>정답</summary>
**상태 분석:**
- Long Scoreboard 60%: 글로벌 메모리 로드 완료를 기다리는 시간이 여전히 지배적이다.
- Wait 25%: `__syncthreads()` 등 동기화 대기도 상당하다.
- 두 스톨이 합쳐서 85%를 차지하므로 연산 유닛은 대부분 유휴 상태이다.

**개선 방향:**
1. **Long Scoreboard 줄이기**: 더블 버퍼링으로 현재 타일 연산과 다음 타일 로드를 오버랩한다. 또는 cp.async를 사용하여 비동기 파이프라인을 구축한다.
2. **Wait 줄이기**: 파이프라인 깊이를 늘려(트리플 버퍼링) `__syncthreads()` 대기 시간을 분산한다. cp.async.wait_group으로 필요한 그룹만 대기할 수 있다.
</details>

### Q7. (Evaluate)
레지스터 블로킹 커널의 점유율이 25%이지만 성능은 타일링 커널(점유율 62%)보다 3배 높다. 이 현상의 원인을 평가하시오.

<details>
<summary>정답</summary>
레지스터 블로킹 커널은 점유율을 희생하여 다음을 얻는다:

1. **산술 강도 대폭 증가**: 스레드당 8×8 = 64개 C 원소를 레지스터에 보관하므로, 공유 메모리에서 한 번 로드한 데이터로 64배 더 많은 연산을 수행한다. 산술 강도가 ~0.5에서 ~8.0 FLOP/byte로 16배 증가한다.

2. **ILP(명령어 수준 병렬성)**: 외적(outer product) 마이크로커널에서 16번의 로드 후 128번의 독립적인 FMA가 이어진다. 이 128개 FMA는 서로 데이터 의존성이 없으므로 파이프라인을 완전히 채울 수 있다.

3. **글로벌 메모리 접근 감소**: 데이터 재사용이 극대화되어 총 메모리 트래픽이 줄어든다.

결론: 메모리 바운드에서 컴퓨트 바운드로 전환되면, 레이턴시를 숨기기 위해 많은 워프가 필요하지 않다. 적은 워프라도 각 워프가 충분한 ILP를 가지면 파이프라인을 채울 수 있다.
</details>

### Q8. (Evaluate)
우리 구현이 cuBLAS의 90%에 도달한 후 추가 최적화의 수익 체감이 심한 이유를 분석하시오.

<details>
<summary>정답</summary>
90% 이후의 추가 최적화가 어려운 이유:

1. **암달의 법칙(Amdahl's Law)**: 전체 실행 시간에서 남은 10%의 비효율은 여러 소규모 요인의 합이다. 한 가지를 개선해도 전체에 미치는 영향이 적다.

2. **하드웨어 한계 접근**: 이미 연산 파이프라인과 메모리 대역폭을 80%+ 활용 중이므로, 남은 개선 여지가 물리적으로 제한된다.

3. **cuBLAS의 비공개 최적화**: 텐서 코어 활용(TF32), 아키텍처별 자동 튜닝, TMA(Tensor Memory Accelerator) 등은 공개 API로 접근하기 어렵거나 아키텍처 세부 지식이 필요하다.

4. **최적화 간 상호작용**: 타일 크기 증가(연산 효율↑)가 점유율을 낮추거나(레이턴시 은닉↓), 공유 메모리 사용량 증가가 동시 블록 수를 줄이는 등, 최적화 간 트레이드오프가 복잡해진다.
</details>

---

## 9. 다음 단계 미리보기

이 모듈에서는 Nsight Compute를 사용한 체계적 성능 분석 방법론을 학습했다. SOL 분석, 스톨 분석, 루프라인 모델을 통해 6개 커널의 성능 차이를 정량적으로 이해하고, 의사결정 트리를 통해 다음 최적화 방향을 판단하는 능력을 갖추었다.

이로써 **SGEMM 최적화의 전체 여정**이 완료되었다:

```
Level 0 (Naive)      →  1-5% cuBLAS    "작동하지만 느리다"
Level 1 (Coalesced)  →  5-10%          "메모리를 효율적으로 읽는다"
Level 2 (Tiled)      →  20-40%         "데이터를 재사용한다"
Level 3 (RegBlock)   →  50-70%         "연산을 극대화한다"
Level 4 (DblBuffer)  →  70-85%         "레이턴시를 숨긴다"
Level 5 (AsyncCopy)  →  85-95%         "하드웨어를 최대한 활용한다"
```

부록에서는 전체 과정의 퀴즈 정답 해설(모듈 12)과 시뮬레이션 상세 가이드(모듈 13)를 제공한다. 이 자료를 활용하여 자신의 이해도를 점검하고, 시뮬레이션을 반복 수행하여 직관을 더욱 단단히 하기 바란다.

---

*이 문서의 참조 파일: `docs/ANALYSIS_GUIDE.md`, `src/benchmark/benchmark_runner.cpp:88-102, 225-249`*
