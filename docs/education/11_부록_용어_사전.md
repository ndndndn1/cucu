# 부록: 용어 사전 (Glossary)

> 이 문서는 BareMetal-SGEMM 프로젝트에서 사용되는 모든 핵심 용어를 정리합니다.
> 각 용어에 한글 번역, 정의, 실제 코드 참조(파일:라인), 첫 등장 모듈을 표기합니다.

---

## 사용법

- 첫 등장 시 **한글 용어(English Term)** 형태로 표기합니다.
- 이후부터는 한글 용어만 사용합니다.
- 코드 참조는 `파일경로:라인번호` 형식입니다.

---

## A

### Arithmetic Intensity (산술 강도)
- **정의**: 전송된 바이트당 수행하는 부동소수점 연산 수 (FLOP/byte). 커널이 메모리 바운드인지 연산 바운드인지 결정하는 핵심 지표.
- **코드**: `include/sgemm_kernels.hpp:187` (`SgemmMetrics::arithmetic_intensity`)
- **수식**: `산술 강도 = 총 FLOP / 총 전송 바이트`
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Async Copy (비동기 복사)
- **정의**: Ampere 이상 GPU에서 지원하는 하드웨어 수준의 비동기 메모리 복사. 글로벌 메모리에서 공유 메모리로 레지스터를 거치지 않고 직접 복사한다.
- **코드**: `src/kernels/sgemm_async_copy.cu:57-61` (`cp.async.cg.shared.global` PTX 명령)
- **첫 등장**: 모듈 9 (Level 5)

---

## B

### Bank Conflict (뱅크 충돌)
- **정의**: 워프 내 여러 스레드가 공유 메모리의 같은 뱅크에 있는 서로 다른 주소에 동시 접근하여 직렬화가 발생하는 현상.
- **코드**: `src/kernels/sgemm_tiled.cu:34-37` (SMEM_PADDING 정의)
- **수식**: `뱅크 번호 = (주소 / 4) % 32`
- **첫 등장**: 모듈 6 (Level 2)

### Block (스레드 블록 / 블록)
- **정의**: GPU에서 함께 실행되는 스레드의 그룹. 하나의 SM에 배정되며 공유 메모리를 공유한다.
- **코드**: `include/cuda_driver_wrapper.hpp:295-307` (`LaunchConfig` 구조체의 `dim3 block`)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### Block Tile (블록 타일)
- **정의**: 하나의 스레드 블록이 담당하는 출력 행렬의 부분 영역. 이 프로젝트에서는 BM x BN = 128 x 128.
- **코드**: `src/kernels/sgemm_register_blocking.cu:35-36` (`#define BM 128`, `#define BN 128`)
- **첫 등장**: 모듈 7 (Level 3)

---

## C

### Cache Line (캐시 라인)
- **정의**: 메모리와 캐시 사이에서 한 번에 전송되는 데이터 단위. GPU에서는 보통 32바이트 또는 128바이트.
- **첫 등장**: 모듈 4 (Level 0)

### Coalescing (코얼레싱 / 메모리 코얼레싱)
- **정의**: 워프 내 연속 스레드가 연속 메모리 주소에 접근할 때, 다수의 개별 접근을 하나의 넓은 메모리 트랜잭션으로 병합하는 하드웨어 메커니즘.
- **코드**: `src/kernels/sgemm_coalesced.cu:23` (`FETCH_FLOAT4` 매크로)
- **첫 등장**: 모듈 5 (Level 1)

### Commit Group (커밋 그룹)
- **정의**: `cp.async.commit_group` PTX 명령으로 현재까지 발행된 비동기 복사를 하나의 그룹으로 묶는 연산.
- **코드**: `src/kernels/sgemm_async_copy.cu:77-79` (`cp_async_commit_group()`)
- **첫 등장**: 모듈 9 (Level 5)

### Compute Bound (연산 바운드)
- **정의**: 커널 성능이 연산 유닛의 처리량에 의해 제한되는 상태. 산술 강도가 높을 때 발생.
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Context (컨텍스트)
- **정의**: CUDA Driver API에서 GPU 장치와의 연결을 관리하는 객체. 모든 CUDA 연산의 범위를 정의한다.
- **코드**: `include/cuda_driver_wrapper.hpp:84-116` (`CudaContext` 클래스)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### cp.async
- **정의**: Ampere(SM 8.0+) 아키텍처에서 도입된 PTX 명령. 글로벌 메모리에서 공유 메모리로 데이터를 레지스터를 우회하여 직접 비동기 복사한다.
- **코드**: `src/kernels/sgemm_async_copy.cu:57-61`
- **PTX**: `cp.async.cg.shared.global [dst], [src], size;`
- **첫 등장**: 모듈 9 (Level 5)

### cuBLAS
- **정의**: NVIDIA가 제공하는 고도로 최적화된 BLAS(Basic Linear Algebra Subprograms) 라이브러리. 이 프로젝트의 성능 비교 기준.
- **코드**: `src/benchmark/cublas_reference.cu` (전체)
- **첫 등장**: 모듈 0 (서론)

---

## D

### Device Memory (디바이스 메모리)
- **정의**: GPU에 할당된 메모리. CUDA Driver API에서는 `cuMemAlloc`으로 할당하며 `CUdeviceptr` 타입으로 참조한다.
- **코드**: `include/cuda_driver_wrapper.hpp:196-221` (`DeviceMemory` 클래스)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### Double Buffering (더블 버퍼링)
- **정의**: 두 개의 공유 메모리 버퍼를 교대로 사용하여, 현재 버퍼에서 연산하는 동안 다음 버퍼에 데이터를 로드하는 소프트웨어 파이프라이닝 기법.
- **코드**: `src/kernels/sgemm_double_buffer.cu:55-56` (`As[2][BM][BK+1]`, `Bs[2][BK][BN+1]`)
- **첫 등장**: 모듈 8 (Level 4)

### Driver API (드라이버 API)
- **정의**: CUDA의 저수준 API. Runtime API와 달리 컨텍스트, 모듈, 함수 핸들을 명시적으로 관리한다.
- **코드**: `include/cuda_driver_wrapper.hpp` (전체 래퍼)
- **주요 함수**: `cuInit`, `cuCtxCreate`, `cuModuleLoadDataEx`, `cuLaunchKernel`
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

---

## F

### FETCH_FLOAT4 (매크로)
- **정의**: 포인터를 `float4*`로 캐스팅하여 128비트(4개 float) 벡터화 로드를 유도하는 매크로.
- **코드**: `src/kernels/sgemm_coalesced.cu:23`
- **구현**: `reinterpret_cast<const float4*>(&(pointer))[0]`
- **첫 등장**: 모듈 5 (Level 1)

### float4
- **정의**: CUDA의 4-성분 벡터 타입. x, y, z, w 멤버를 가지며 16바이트(128비트) 정렬. 벡터화 로드/스토어에 사용.
- **첫 등장**: 모듈 5 (Level 1)

### FLOP (부동소수점 연산)
- **정의**: Floating-Point Operation. 하나의 부동소수점 덧셈 또는 곱셈. FMA는 2 FLOP으로 계산.
- **코드**: `include/sgemm_kernels.hpp:195-198` (`sgemm_flops()` 함수)
- **수식**: SGEMM의 총 FLOP = `2 * M * N * K`
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### FMA (Fused Multiply-Add / 융합 곱셈-덧셈)
- **정의**: `d = a * b + c`를 단일 명령어로 수행하는 연산. 2 FLOP을 1 사이클에 수행하며, 중간 라운딩 오류가 없다.
- **코드**: `src/kernels/sgemm_tiled.cu:173-177` (인라인 PTX)
- **PTX**: `fma.rn.f32 %0, %1, %2, %0;`
- **SASS**: `FFMA` 명령어
- **첫 등장**: 모듈 6 (Level 2)

---

## G

### GFLOP/s (기가 FLOP/초)
- **정의**: 초당 수행하는 부동소수점 연산 수 (10^9 FLOP/s). GPU 커널의 연산 처리량 지표.
- **코드**: `include/sgemm_kernels.hpp:185` (`SgemmMetrics::gflops`)
- **수식**: `GFLOP/s = 총 FLOP / (실행 시간(초) * 10^9)`
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Global Memory (글로벌 메모리)
- **정의**: GPU의 DRAM. 가장 크지만 가장 느린 메모리 계층. 접근 지연시간 ~400-600 사이클.
- **코드**: `include/cuda_driver_wrapper.hpp:59` (`DeviceInfo::total_memory`)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### Grid (그리드)
- **정의**: 커널 실행 시 생성되는 스레드 블록들의 집합. 1, 2, 또는 3차원으로 구성.
- **코드**: `include/cuda_driver_wrapper.hpp:296` (`LaunchConfig::grid`)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

---

## I

### ILP (Instruction-Level Parallelism / 명령어 수준 병렬성)
- **정의**: 단일 스레드 내에서 독립적인 명령어를 동시에 실행할 수 있는 정도. 레지스터 블로킹에서 64개의 독립 FMA가 높은 ILP를 제공한다.
- **첫 등장**: 모듈 7 (Level 3)

### Inline PTX (인라인 PTX)
- **정의**: CUDA 커널 코드 내에서 `asm volatile(...)` 구문으로 직접 PTX 어셈블리를 삽입하는 기법.
- **코드**: `src/kernels/sgemm_tiled.cu:173-177`
- **용도**: FMA 보장, cp.async 사용, 캐시 힌트 지정
- **첫 등장**: 모듈 6 (Level 2)

---

## J

### JIT Compilation (JIT 컴파일 / 즉시 컴파일)
- **정의**: PTX 중간 표현을 실행 시점에 대상 GPU의 기계어(SASS)로 컴파일하는 방식. 아키텍처 이식성을 제공한다.
- **코드**: `src/driver/kernel_launcher.cpp:61` (`CudaModule::from_ptx()`)
- **Driver API**: `cuModuleLoadDataEx()`
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

---

## K

### Kernel (커널)
- **정의**: GPU에서 실행되는 함수. `__global__` 키워드로 선언하며, 수천~수백만 스레드가 병렬 실행한다.
- **코드**: `src/kernels/sgemm_naive.cu:20-50` (나이브 커널 예시)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

---

## L

### Launch Configuration (실행 구성)
- **정의**: 커널 실행 시 지정하는 그리드 크기, 블록 크기, 공유 메모리 크기의 조합.
- **코드**: `include/cuda_driver_wrapper.hpp:295-307` (`LaunchConfig` 구조체)
- **코드**: `src/driver/kernel_launcher.cpp:70-114` (`get_launch_config()`)
- **첫 등장**: 모듈 4 (Level 0)

### LDG.E.128 (SASS 명령어)
- **정의**: 128비트(16바이트) 글로벌 메모리 로드 SASS 명령어. float4 벡터화 로드가 성공적으로 생성되었음을 나타낸다.
- **비교**: `LDG.E` (32비트 로드, 비효율적)
- **첫 등장**: 모듈 5 (Level 1)

### LDGSTS (SASS 명령어)
- **정의**: Load Global Store Shared. cp.async의 하드웨어 구현 명령어. 글로벌에서 공유 메모리로 직접 복사.
- **코드**: `src/kernels/sgemm_async_copy.cu:457` (주석에서 설명)
- **첫 등장**: 모듈 9 (Level 5)

### Leading Dimension (리딩 디멘션)
- **정의**: 행렬의 행 사이 메모리 간격(바이트가 아닌 원소 수). Row-major에서 행의 열 수와 같거나 그 이상.
- **코드**: `include/sgemm_kernels.hpp:118-120` (`lda`, `ldb`, `ldc`)
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Long Scoreboard (롱 스코어보드)
- **정의**: Nsight Compute의 스톨 원인. 글로벌 메모리 로드 결과를 기다리느라 워프가 멈추는 상태.
- **코드**: `docs/ANALYSIS_GUIDE.md:54-59`
- **해결**: 더블 버퍼링, cp.async
- **첫 등장**: 모듈 10 (종합 성능분석)

---

## M

### Math Pipe Throttle (수학 파이프 스로틀)
- **정의**: Nsight Compute의 스톨 원인. 연산 파이프라인이 포화 상태임을 나타냄. 이것이 주요 스톨이면 최적 상태이다.
- **코드**: `docs/ANALYSIS_GUIDE.md:68-69`
- **첫 등장**: 모듈 10 (종합 성능분석)

### Memory Bound (메모리 바운드)
- **정의**: 커널 성능이 메모리 대역폭에 의해 제한되는 상태. 산술 강도가 낮을 때 발생.
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Micro-kernel (마이크로커널)
- **정의**: 가장 안쪽의 연산 루프. 레지스터에서 직접 수행되는 외적(outer product) 연산 단위.
- **코드**: `src/kernels/sgemm_register_blocking.cu:142-166`
- **첫 등장**: 모듈 7 (Level 3)

---

## N

### Nsight Compute
- **정의**: NVIDIA의 GPU 커널 프로파일링 도구. SASS 분석, SOL 분석, 스톨 원인 파악 등에 사용.
- **코드**: `docs/ANALYSIS_GUIDE.md` (전체)
- **실행**: `ncu --set full -o profile ./sgemm_benchmark`
- **첫 등장**: 모듈 10 (종합 성능분석)

### NUM_STAGES (파이프라인 단계 수)
- **정의**: 비동기 복사 파이프라인의 깊이. 트리플 버퍼링에서 NUM_STAGES = 3.
- **코드**: `src/kernels/sgemm_async_copy.cu:40` (`#define NUM_STAGES 3`)
- **첫 등장**: 모듈 9 (Level 5)

---

## O

### Occupancy (점유율)
- **정의**: SM당 활성 워프 수 대비 최대 워프 수의 비율. 레지스터, 공유 메모리, 블록 크기에 의해 결정된다.
- **코드**: `src/driver/kernel_launcher.cpp:137-149` (`get_occupancy()`)
- **수식**: `점유율 = 활성 워프 / SM당 최대 워프`
- **주의**: 높은 점유율 != 높은 성능 (ILP가 보상 가능)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### OptLevel (최적화 레벨)
- **정의**: 이 프로젝트에서 정의한 6단계 최적화 수준의 열거형.
- **코드**: `include/sgemm_kernels.hpp:61-68`
- **값**: Naive(0), Coalesced(1), Tiled(2), RegisterBlocking(3), DoubleBuffer(4), AsyncCopy(5)
- **첫 등장**: 모듈 0 (서론)

### Outer Product (외적)
- **정의**: 벡터 a(크기 m)와 벡터 b(크기 n)의 외적으로 m x n 행렬을 생성하는 연산. `C[i][j] += a[i] * b[j]`. 레지스터 블로킹의 핵심 연산 패턴.
- **코드**: `src/kernels/sgemm_register_blocking.cu:158-165`
- **첫 등장**: 모듈 7 (Level 3)

---

## P

### Padding (패딩)
- **정의**: 공유 메모리 배열의 각 행 끝에 추가하는 여분의 원소. 뱅크 충돌을 방지하기 위해 행의 시작 뱅크를 이동시킨다.
- **코드**: `src/kernels/sgemm_tiled.cu:37` (`#define SMEM_PADDING 1`)
- **예시**: `__shared__ float A_tile[16][16 + 1]` - +1 패딩
- **첫 등장**: 모듈 6 (Level 2)

### Peak Performance (피크 성능)
- **정의**: GPU의 이론적 최대 연산 처리량. SM 수 x SM당 FP32 코어 수 x 클럭 주파수 x 2 (FMA).
- **코드**: `src/benchmark/benchmark_runner.cpp:88-102` (피크 성능 계산)
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Pinned Memory (고정 메모리 / 페이지 잠금 메모리)
- **정의**: 호스트에서 페이지 아웃되지 않도록 잠긴 메모리. DMA를 통한 비동기 전송에 필요.
- **코드**: `include/cuda_driver_wrapper.hpp:226-245` (`PinnedMemory` 클래스)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### Prologue (프롤로그)
- **정의**: 더블/트리플 버퍼링에서 메인 루프 시작 전에 첫 타일을 미리 로드하는 초기화 단계.
- **코드**: `src/kernels/sgemm_double_buffer.cu:132-137`
- **코드**: `src/kernels/sgemm_async_copy.cu:193-196`
- **첫 등장**: 모듈 8 (Level 4)

### PTX (Parallel Thread Execution)
- **정의**: CUDA의 중간 표현(IR) 언어. GPU의 "어셈블리"에 해당하며, JIT 컴파일을 통해 실제 기계어(SASS)로 변환된다.
- **코드**: `src/driver/kernel_launcher.cpp:43-68` (PTX 파일 로드 및 JIT 컴파일)
- **빌드**: `CMakeLists.txt:54-66` (nvcc -ptx로 생성)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

---

## R

### RAII (Resource Acquisition Is Initialization)
- **정의**: C++ 디자인 패턴. 객체 생성 시 리소스를 획득하고 소멸 시 자동 해제한다. CUDA 리소스 누수 방지에 사용.
- **코드**: `include/cuda_driver_wrapper.hpp:84-116` (`CudaContext`), `:196-221` (`DeviceMemory`)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### Register (레지스터)
- **정의**: GPU의 가장 빠른 메모리. 스레드 전용(private). 접근 지연시간 ~1 사이클.
- **SM당 총량**: 65536개 (Ampere)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### Register Blocking (레지스터 블로킹)
- **정의**: 각 스레드가 다수의 출력 원소(예: 8x8 = 64개)를 레지스터에 축적하여 산술 강도를 높이는 최적화 기법.
- **코드**: `src/kernels/sgemm_register_blocking.cu:80-85` (`reg_C[TM][TN]`, `reg_A[TM]`, `reg_B[TN]`)
- **첫 등장**: 모듈 7 (Level 3)

### Register Spilling (레지스터 스필링)
- **정의**: 스레드의 레지스터 수요가 하드웨어 한계(255)를 초과하여 로컬 메모리(느림)에 값을 저장하는 현상. 성능을 크게 저하시킨다.
- **SASS 확인**: `LDL`(Load Local), `STL`(Store Local) 명령어 존재 여부
- **코드**: `docs/ANALYSIS_GUIDE.md:128-139`
- **첫 등장**: 모듈 7 (Level 3)

### Roofline Model (루프라인 모델)
- **정의**: 커널 성능의 상한을 피크 연산 처리량과 메모리 대역폭의 함수로 나타내는 성능 모델. `성능 <= min(피크연산, 피크대역폭 * 산술강도)`.
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Row-major (행 우선 저장)
- **정의**: 2차원 배열을 메모리에 행 단위로 연속 저장하는 방식. `A[i][j]`는 주소 `A + i * cols + j`에 위치.
- **코드**: `include/sgemm_kernels.hpp:115` ("MxK, row-major" 주석)
- **첫 등장**: 모듈 3 (행렬곱셈 수학적 배경)

### Runtime API (런타임 API)
- **정의**: CUDA의 고수준 API. 컨텍스트 관리가 암시적이며 `<<<>>>` 구문으로 커널을 실행한다. Driver API보다 편리하지만 세밀한 제어가 어렵다.
- **비교**: `include/cuda_driver_wrapper.hpp:1-14` (Driver API vs Runtime API 설명)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

---

## S

### SASS (Shader Assembly)
- **정의**: GPU의 기계어 코드. PTX가 JIT 컴파일된 최종 결과물. Nsight Compute에서 확인 가능.
- **주요 명령어**: `LDG.E.128`, `LDGSTS`, `FFMA`, `LDL`/`STL`
- **첫 등장**: 모듈 5 (Level 1)

### Sectors/Request (섹터/요청)
- **정의**: Nsight Compute 메트릭. 하나의 메모리 요청이 발생시키는 캐시 섹터 수. 이상적인 값은 1.0 (완벽한 코얼레싱).
- **코드**: `docs/ANALYSIS_GUIDE.md:79-83`
- **첫 등장**: 모듈 10 (종합 성능분석)

### SGEMM (단정밀도 일반 행렬곱)
- **정의**: Single-precision General Matrix Multiplication. `C = alpha * A * B + beta * C` 연산.
- **코드**: `include/sgemm_kernels.hpp:16-17`
- **첫 등장**: 모듈 0 (서론)

### Shared Memory (공유 메모리)
- **정의**: SM 내 블록 단위로 공유되는 빠른 온칩 메모리. 접근 지연시간 ~20-30 사이클. 32개 뱅크 구조.
- **코드**: `src/kernels/sgemm_tiled.cu:55-56` (`__shared__` 키워드)
- **첫 등장**: 모듈 1 (GPU 아키텍처), 상세 모듈 6 (Level 2)

### SIMT (Single Instruction Multiple Thread)
- **정의**: GPU의 실행 모델. 하나의 명령어를 워프 내 32개 스레드가 동시에 실행한다.
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### SM (Streaming Multiprocessor)
- **정의**: GPU의 핵심 연산 유닛. 여러 워프를 병렬 실행하며 레지스터 파일, 공유 메모리, L1 캐시를 포함한다.
- **코드**: `include/cuda_driver_wrapper.hpp:60` (`DeviceInfo::sm_count`)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### SOL (Speed of Light)
- **정의**: Nsight Compute에서 이론적 최대 성능 대비 달성 비율. SM Throughput과 Memory Throughput 두 지표로 구성.
- **코드**: `docs/ANALYSIS_GUIDE.md:26-48`
- **첫 등장**: 모듈 10 (종합 성능분석)

### Software Pipelining (소프트웨어 파이프라이닝)
- **정의**: 메모리 로드와 연산을 시간적으로 중첩하여 메모리 지연시간을 숨기는 기법. 더블/트리플 버퍼링으로 구현.
- **코드**: `src/kernels/sgemm_double_buffer.cu:139-156` (메인 루프)
- **첫 등장**: 모듈 8 (Level 4)

### Stream (스트림)
- **정의**: GPU 명령어의 순서 있는 대기열. 같은 스트림 내 명령어는 순차 실행, 다른 스트림은 병렬 실행 가능.
- **코드**: `include/cuda_driver_wrapper.hpp:250-266` (`CudaStream` 클래스)
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### __syncthreads() (동기화 배리어)
- **정의**: 블록 내 모든 스레드가 이 지점에 도달할 때까지 대기하는 동기화 명령. 공유 메모리의 데이터 정합성 보장에 필수.
- **코드**: `src/kernels/sgemm_tiled.cu:93, 105` (로드 후, 연산 후 각각 필요)
- **첫 등장**: 모듈 6 (Level 2)

---

## T

### Thread (스레드)
- **정의**: GPU 실행의 가장 작은 단위. 고유한 `threadIdx`를 가지며 레지스터는 전용, 공유 메모리는 블록 내 공유.
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### Thread Coarsening (스레드 조잡화)
- **정의**: 각 스레드가 더 많은 작업을 수행하도록 설계하는 최적화 기법. 나이브: 1 원소/스레드 -> 레지스터 블로킹: 64 원소/스레드.
- **코드**: `src/kernels/sgemm_register_blocking.cu:38-39` (`TM=8`, `TN=8`)
- **첫 등장**: 모듈 7 (Level 3)

### Thread Tile (스레드 타일)
- **정의**: 하나의 스레드가 담당하는 출력 행렬의 부분 영역. 이 프로젝트에서는 TM x TN = 8 x 8.
- **코드**: `include/sgemm_kernels.hpp:38-39` (`THREAD_TILE_M`, `THREAD_TILE_N`)
- **첫 등장**: 모듈 7 (Level 3)

### Tiling (타일링)
- **정의**: 큰 행렬을 작은 타일(sub-matrix)로 분할하여 빠른 메모리(공유 메모리)에 올리고 재사용하는 기법.
- **코드**: `src/kernels/sgemm_tiled.cu:72-106` (타일 루프)
- **첫 등장**: 모듈 6 (Level 2)

### Triple Buffering (트리플 버퍼링)
- **정의**: 세 개의 공유 메모리 버퍼를 순환 사용하여 파이프라인 깊이를 증가시키는 기법. cp.async와 함께 사용하여 최대 레이턴시 은닉.
- **코드**: `src/kernels/sgemm_async_copy.cu:40, 119-120` (`NUM_STAGES=3`, `As[3][...]`)
- **첫 등장**: 모듈 9 (Level 5)

---

## V

### Vectorized Load (벡터화 로드)
- **정의**: 단일 명령어로 여러 데이터 원소를 동시에 로드하는 기법. float4로 4개 float(128비트)를 한 번에 로드.
- **코드**: `src/kernels/sgemm_coalesced.cu:52-54` (FETCH_FLOAT4 사용)
- **SASS**: `LDG.E.128`
- **첫 등장**: 모듈 5 (Level 1)

---

## W

### Wait Group (대기 그룹)
- **정의**: `cp.async.wait_group N` PTX 명령. 최대 N개의 비동기 복사 그룹이 미완료 상태가 될 때까지 대기한다.
- **코드**: `src/kernels/sgemm_async_copy.cu:83-94` (`cp_async_wait_group()`)
- **첫 등장**: 모듈 9 (Level 5)

### Warp (워프)
- **정의**: 32개 스레드로 구성된 GPU 실행의 기본 스케줄링 단위. 워프 내 스레드는 동일한 명령어를 동시에 실행한다(SIMT).
- **코드**: `include/sgemm_kernels.hpp:42` (`constexpr int WARP_SIZE = 32`)
- **첫 등장**: 모듈 1 (GPU 아키텍처)

### Wavefronts Shared Excessive (공유 메모리 과잉 웨이브프론트)
- **정의**: Nsight Compute 메트릭. 뱅크 충돌로 인해 발생하는 추가 메모리 트랜잭션의 비율. 이상적인 값은 1.0.
- **코드**: `docs/ANALYSIS_GUIDE.md:96-103`
- **첫 등장**: 모듈 6 (Level 2), 상세 모듈 10

---

## 기호/숫자

### __global__
- **정의**: CUDA 함수 한정자. GPU에서 실행되고 호스트(CPU)에서 호출 가능한 커널 함수를 선언한다.
- **코드**: `src/kernels/sgemm_naive.cu:20`
- **첫 등장**: 모듈 2 (CUDA 프로그래밍 기초)

### __restrict__
- **정의**: 포인터 별칭(alias)이 없음을 컴파일러에 알려 최적화를 가능하게 하는 키워드.
- **코드**: `src/kernels/sgemm_naive.cu:21-23` (모든 커널 파라미터에 사용)
- **첫 등장**: 모듈 4 (Level 0)

### __shared__
- **정의**: 변수를 공유 메모리에 할당하는 CUDA 메모리 공간 한정자. 블록 내 모든 스레드가 접근 가능.
- **코드**: `src/kernels/sgemm_tiled.cu:55-56`
- **첫 등장**: 모듈 6 (Level 2)

### #pragma unroll
- **정의**: 컴파일러에게 루프를 완전히 언롤링(펼침)하도록 지시하는 힌트. 분기 오버헤드 제거, ILP 증가.
- **코드**: `src/kernels/sgemm_tiled.cu:98` (내부 K 루프)
- **코드**: `src/kernels/sgemm_register_blocking.cu:141, 145, 152, 159, 161` (다단계 언롤링)
- **첫 등장**: 모듈 6 (Level 2)
